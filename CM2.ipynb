{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CM2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Churn Modeling \n",
        "Binary classification using embeddings of categorical features.\n",
        "\n",
        "#### Dataset:\n",
        "The dataset used for this experiment is provided in https://github.com/sharmaroshan/Churn-Modelling-Dataset\n",
        "\n",
        "Balance of Data: \n",
        "{1: 0.2037, 0: 0.7963}\n",
        "\n",
        "### Pipelines:\n",
        "1. Package categorical features together and separate those from numerical features.\n",
        "2. Package each categorical features separately and separate from numerical features.\n",
        "\n",
        "### Modeling:\n",
        "Used both Tensorflow and Pytorch to achieve an 85% accuracy on test data. The aim was to compare the performance of these two packages on the same dataset. \n",
        "\n",
        "It would be nice to compare with the performance of tree-based models.\n",
        "\n"
      ],
      "metadata": {
        "id": "_GYcSPfsxqdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/sharmaroshan/Churn-Modelling-Dataset/master/Churn_Modelling.csv'\n",
        "df = pd.read_csv(url, index_col=0)\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "jhz_qOHqxOk3",
        "outputId": "83ce2449-94c1-4a1c-b6d9-dd80a2c84390"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 13)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10000 entries, 1 to 10000\n",
            "Data columns (total 13 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   CustomerId       10000 non-null  int64  \n",
            " 1   Surname          10000 non-null  object \n",
            " 2   CreditScore      10000 non-null  int64  \n",
            " 3   Geography        10000 non-null  object \n",
            " 4   Gender           10000 non-null  object \n",
            " 5   Age              10000 non-null  int64  \n",
            " 6   Tenure           10000 non-null  int64  \n",
            " 7   Balance          10000 non-null  float64\n",
            " 8   NumOfProducts    10000 non-null  int64  \n",
            " 9   HasCrCard        10000 non-null  int64  \n",
            " 10  IsActiveMember   10000 non-null  int64  \n",
            " 11  EstimatedSalary  10000 non-null  float64\n",
            " 12  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           CustomerId   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
              "RowNumber                                                                     \n",
              "1            15634602  Hargrave          619    France  Female   42       2   \n",
              "2            15647311      Hill          608     Spain  Female   41       1   \n",
              "3            15619304      Onio          502    France  Female   42       8   \n",
              "4            15701354      Boni          699    France  Female   39       1   \n",
              "5            15737888  Mitchell          850     Spain  Female   43       2   \n",
              "\n",
              "             Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "RowNumber                                                        \n",
              "1               0.00              1          1               1   \n",
              "2           83807.86              1          0               1   \n",
              "3          159660.80              3          1               0   \n",
              "4               0.00              2          0               0   \n",
              "5          125510.82              1          1               1   \n",
              "\n",
              "           EstimatedSalary  Exited  \n",
              "RowNumber                           \n",
              "1                101348.88       1  \n",
              "2                112542.58       0  \n",
              "3                113931.57       1  \n",
              "4                 93826.63       0  \n",
              "5                 79084.10       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dc7a807-757e-43ed-aee5-bd32127b7e9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dc7a807-757e-43ed-aee5-bd32127b7e9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1dc7a807-757e-43ed-aee5-bd32127b7e9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1dc7a807-757e-43ed-aee5-bd32127b7e9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "c = Counter(df['Exited'])\n",
        "precentages = {k:v/df.shape[0] for k,v in c.items()}\n",
        "print(c)\n",
        "print(f'percentages: {precentages}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEn6PFGiAvGp",
        "outputId": "66d64114-f932-48f9-afb0-a8733d4a1490"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 7963, 1: 2037})\n",
            "percentages: {1: 0.2037, 0: 0.7963}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
        "numerical_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "outputs = ['Exited']\n",
        "\n",
        "cat_count = len(categorical_columns)\n",
        "num_count = len(numerical_columns)\n",
        "\n",
        "print(cat_count + num_count)\n",
        "categorical_embedding_sizes = {}\n",
        "\n",
        "for category in categorical_columns:\n",
        "    df[category] = df[category].astype('category')\n",
        "    cz = len(df[category].cat.categories)\n",
        "    categorical_embedding_sizes[category] = (cz,min(50, (cz+1)//2))\n",
        "    df[category] = df[category].cat.codes.values\n",
        "\n",
        "print(categorical_embedding_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdFvyxlSAyex",
        "outputId": "cb6ca0fa-b021-4909-fb2b-e5b18e0e47eb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "{'Geography': (3, 2), 'Gender': (2, 1), 'HasCrCard': (2, 1), 'IsActiveMember': (2, 1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mns = MinMaxScaler()\n",
        "df[numerical_columns] = mns.fit_transform(df[numerical_columns])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pyrhB-MZckz9",
        "outputId": "d57c35a2-e05a-4936-fd8f-4f44c50dd73f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           CustomerId   Surname  CreditScore  Geography  Gender       Age  \\\n",
              "RowNumber                                                                   \n",
              "1            15634602  Hargrave        0.538          0       0  0.324324   \n",
              "2            15647311      Hill        0.516          2       0  0.310811   \n",
              "3            15619304      Onio        0.304          0       0  0.324324   \n",
              "4            15701354      Boni        0.698          0       0  0.283784   \n",
              "5            15737888  Mitchell        1.000          2       0  0.337838   \n",
              "\n",
              "           Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "RowNumber                                                               \n",
              "1             0.2  0.000000       0.000000          1               1   \n",
              "2             0.1  0.334031       0.000000          0               1   \n",
              "3             0.8  0.636357       0.666667          1               0   \n",
              "4             0.1  0.000000       0.333333          0               0   \n",
              "5             0.2  0.500246       0.000000          1               1   \n",
              "\n",
              "           EstimatedSalary  Exited  \n",
              "RowNumber                           \n",
              "1                 0.506735       1  \n",
              "2                 0.562709       0  \n",
              "3                 0.569654       1  \n",
              "4                 0.469120       0  \n",
              "5                 0.395400       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c183861-3ecd-49bc-852b-32390dc4b01f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>0.538</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506735</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>0.516</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.310811</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.334031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.562709</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>0.304</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.636357</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.569654</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>0.698</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469120</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.337838</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.500246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.395400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c183861-3ecd-49bc-852b-32390dc4b01f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c183861-3ecd-49bc-852b-32390dc4b01f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c183861-3ecd-49bc-852b-32390dc4b01f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[categorical_columns + numerical_columns]\n",
        "y = df[outputs]\n",
        "\n",
        "for col in categorical_columns:\n",
        "  X[col] = X[col].astype(float)\n",
        "\n",
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpi3MwBbA2Ef",
        "outputId": "186e3dbe-e6fe-4090-eb12-191bb151a49f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10000 entries, 1 to 10000\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Geography        10000 non-null  float64\n",
            " 1   Gender           10000 non-null  float64\n",
            " 2   HasCrCard        10000 non-null  float64\n",
            " 3   IsActiveMember   10000 non-null  float64\n",
            " 4   CreditScore      10000 non-null  float64\n",
            " 5   Age              10000 non-null  float64\n",
            " 6   Tenure           10000 non-null  float64\n",
            " 7   Balance          10000 non-null  float64\n",
            " 8   NumOfProducts    10000 non-null  float64\n",
            " 9   EstimatedSalary  10000 non-null  float64\n",
            "dtypes: float64(10)\n",
            "memory usage: 859.4 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train,y_train,test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "3Xc0jAYLBC2Y"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flattened Input"
      ],
      "metadata": {
        "id": "l-TXJMpltGEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Numpy array construction\n",
        "import numpy as np\n",
        "\n",
        "X_train_cat = np.stack([X_train[col].values for col in categorical_columns], 1)\n",
        "X_train_num = np.stack([X_train[col].values for col in numerical_columns],1)\n",
        "y_train = np.reshape(y_train.values,y_train.shape[0])\n",
        "print(X_train_cat.shape,X_train_num.shape,y_train.shape)\n",
        "\n",
        "X_test_cat = np.stack([X_test[col].values for col in categorical_columns], 1)\n",
        "X_test_num = np.stack([X_test[col].values for col in numerical_columns],1)\n",
        "y_test = np.reshape(y_test.values,y_test.shape[0])\n",
        "print(X_test_cat.shape,X_test_num.shape,y_test.shape)\n",
        "\n",
        "X_eval_cat = np.stack([X_eval[col].values for col in categorical_columns], 1)\n",
        "X_eval_num = np.stack([X_eval[col].values for col in numerical_columns],1)\n",
        "y_eval = np.reshape(y_eval.values,y_eval.shape[0])\n",
        "print(X_eval_cat.shape,X_eval_num.shape,y_eval.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwDAOb-fBgo2",
        "outputId": "9d549f2a-fa3c-41cd-8c39-dfce9de1128d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7200, 4) (7200, 6) (7200,)\n",
            "(2000, 4) (2000, 6) (2000,)\n",
            "(800, 4) (800, 6) (800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "c = Counter(y_train)\n",
        "print(c)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHW34Gdp4mdj",
        "outputId": "0be1c5f3-3664-49c5-d13f-cb47c4bd7a3b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 5709, 1: 1491})\n",
            "[1 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Section"
      ],
      "metadata": {
        "id": "9hExoKHBN8_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tensorflow tensor construction\n",
        "import tensorflow as tf\n",
        "\n",
        "X_train_cat = tf.convert_to_tensor(X_train_cat,dtype = tf.int64)\n",
        "X_train_num = tf.convert_to_tensor(X_train_num,dtype = tf.float64)\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "\n",
        "X_test_cat = tf.convert_to_tensor(X_test_cat,dtype = tf.int64)\n",
        "X_test_num = tf.convert_to_tensor(X_test_num,dtype = tf.float64)\n",
        "y_test = tf.convert_to_tensor(y_test)\n",
        "\n",
        "X_eval_cat = tf.convert_to_tensor(X_eval_cat,dtype = tf.int64)\n",
        "X_eval_num = tf.convert_to_tensor(X_eval_num,dtype = tf.float64)\n",
        "y_eval = tf.convert_to_tensor(y_eval)"
      ],
      "metadata": {
        "id": "OgyTJusDDrvh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_input = tf.keras.Input(shape=(cat_count))\n",
        "num_input = tf.keras.Input(shape=(num_count))\n",
        "emb_layers = []\n",
        "for i,col in enumerate(categorical_columns):\n",
        "  em_size = categorical_embedding_sizes[col]\n",
        "  emb_layers.append(tf.keras.layers.Embedding(em_size[0],em_size[1])(cat_input[:,i]))\n",
        "merge = tf.keras.layers.Concatenate(axis=1)(emb_layers)\n",
        "x2 = tf.keras.layers.concatenate([merge,num_input])\n",
        "x3 = tf.keras.layers.Dense(5,activation='relu')(x2)\n",
        "x7 = tf.keras.layers.Dense(2,activation='softmax')(x3)\n",
        "out_layer = x7\n",
        "model = tf.keras.Model(inputs=[cat_input,num_input], outputs=out_layer)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "0sYAJV5IK8yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed291676-2aba-4e78-918c-3d1a3121e4a5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_30 (InputLayer)          [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None,)             0           ['input_30[0][0]']               \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None,)             0           ['input_30[0][0]']               \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_10 (S  (None,)             0           ['input_30[0][0]']               \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_11 (S  (None,)             0           ['input_30[0][0]']               \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " embedding_28 (Embedding)       (None, 2)            6           ['tf.__operators__.getitem_8[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " embedding_29 (Embedding)       (None, 1)            2           ['tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " embedding_30 (Embedding)       (None, 1)            2           ['tf.__operators__.getitem_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_31 (Embedding)       (None, 1)            2           ['tf.__operators__.getitem_11[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 5)            0           ['embedding_28[0][0]',           \n",
            "                                                                  'embedding_29[0][0]',           \n",
            "                                                                  'embedding_30[0][0]',           \n",
            "                                                                  'embedding_31[0][0]']           \n",
            "                                                                                                  \n",
            " input_31 (InputLayer)          [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 11)           0           ['concatenate_9[0][0]',          \n",
            "                                                                  'input_31[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 5)            60          ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 2)            12          ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 84\n",
            "Trainable params: 84\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test input/output shapes\n",
        "print('input:')\n",
        "print(X_eval_cat[:1])\n",
        "print(X_eval_num[:1])\n",
        "print('output:')\n",
        "print(model([X_eval_cat[:1],X_eval_num[:1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oowx2zg2X0KI",
        "outputId": "e7733368-115e-4fc5-f08d-754922d618b1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:\n",
            "tf.Tensor([[0 0 1 1]], shape=(1, 4), dtype=int64)\n",
            "tf.Tensor([[0.902      0.18918919 0.4        0.29960587 0.         0.18945269]], shape=(1, 6), dtype=float64)\n",
            "output:\n",
            "tf.Tensor([[0.2678597 0.7321403]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "          metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],)\n",
        "model.fit([X_train_cat,X_train_num], y_train, epochs=50, batch_size=8)#,validation_data=(X_eval, y_eval))\n",
        "_, accuracy = model.evaluate([X_test_cat,X_test_num], y_test, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6cyK_j2ggk3",
        "outputId": "724bdbea-9961-4d93-b9dc-1013878b6cc9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.4740 - acc: 0.7901\n",
            "Epoch 2/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4406 - acc: 0.8036\n",
            "Epoch 3/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4403 - acc: 0.8071\n",
            "Epoch 4/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4381 - acc: 0.8067\n",
            "Epoch 5/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4376 - acc: 0.8061\n",
            "Epoch 6/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4364 - acc: 0.8111\n",
            "Epoch 7/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4348 - acc: 0.8094\n",
            "Epoch 8/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4312 - acc: 0.8122\n",
            "Epoch 9/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4186 - acc: 0.8238\n",
            "Epoch 10/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4097 - acc: 0.8315\n",
            "Epoch 11/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4068 - acc: 0.8296\n",
            "Epoch 12/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4063 - acc: 0.8296\n",
            "Epoch 13/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4060 - acc: 0.8289\n",
            "Epoch 14/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4037 - acc: 0.8313\n",
            "Epoch 15/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4032 - acc: 0.8321\n",
            "Epoch 16/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4037 - acc: 0.8339\n",
            "Epoch 17/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4034 - acc: 0.8331\n",
            "Epoch 18/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4026 - acc: 0.8347\n",
            "Epoch 19/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4008 - acc: 0.8346\n",
            "Epoch 20/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4013 - acc: 0.8365\n",
            "Epoch 21/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4008 - acc: 0.8389\n",
            "Epoch 22/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4009 - acc: 0.8371\n",
            "Epoch 23/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4005 - acc: 0.8374\n",
            "Epoch 24/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3996 - acc: 0.8376\n",
            "Epoch 25/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.4002 - acc: 0.8394\n",
            "Epoch 26/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3999 - acc: 0.8361\n",
            "Epoch 27/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3994 - acc: 0.8386\n",
            "Epoch 28/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3996 - acc: 0.8363\n",
            "Epoch 29/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3990 - acc: 0.8367\n",
            "Epoch 30/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3997 - acc: 0.8368\n",
            "Epoch 31/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3988 - acc: 0.8400\n",
            "Epoch 32/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3987 - acc: 0.8369\n",
            "Epoch 33/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3983 - acc: 0.8378\n",
            "Epoch 34/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3995 - acc: 0.8376\n",
            "Epoch 35/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3989 - acc: 0.8371\n",
            "Epoch 36/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3968 - acc: 0.8400\n",
            "Epoch 37/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3976 - acc: 0.8388\n",
            "Epoch 38/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3990 - acc: 0.8369\n",
            "Epoch 39/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3979 - acc: 0.8363\n",
            "Epoch 40/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3967 - acc: 0.8354\n",
            "Epoch 41/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3849 - acc: 0.8354\n",
            "Epoch 42/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3797 - acc: 0.8421\n",
            "Epoch 43/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3746 - acc: 0.8450\n",
            "Epoch 44/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3720 - acc: 0.8446\n",
            "Epoch 45/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3689 - acc: 0.8486\n",
            "Epoch 46/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3666 - acc: 0.8479\n",
            "Epoch 47/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3647 - acc: 0.8501\n",
            "Epoch 48/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3630 - acc: 0.8521\n",
            "Epoch 49/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3617 - acc: 0.8500\n",
            "Epoch 50/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3595 - acc: 0.8531\n",
            "Accuracy: 86.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = model.evaluate([X_train_cat,X_train_num], y_train)\n",
        "_, test_acc = model.evaluate([X_test_cat,X_test_num], y_test)\n",
        "y_pred = [list(x).index(max(x)) for x in model.predict([X_test_cat,X_test_num])]\n",
        "\n",
        "print('First Model Acc:')\n",
        "print(\"train acc\", train_acc)\n",
        "print(\" test acc\", test_acc)\n",
        "print(tf.math.confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AyBh96yhe3U",
        "outputId": "5370c5cc-d3d7-4fb5-e7c2-f755c77d0056"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 1s 2ms/step - loss: 0.3535 - acc: 0.8550\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3486 - acc: 0.8605\n",
            "First Model Acc:\n",
            "train acc 0.8550000190734863\n",
            " test acc 0.8604999780654907\n",
            "tf.Tensor(\n",
            "[[1562   45]\n",
            " [ 234  159]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch Section"
      ],
      "metadata": {
        "id": "oF-iG2kkOAmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X_train_cat = torch.tensor(X_train_cat, dtype=torch.int64)\n",
        "X_train_num = torch.tensor(X_train_num,dtype=torch.float)\n",
        "y_train = torch.tensor(y_train)\n",
        "print(X_train_cat.shape,X_train_num.shape,y_train.shape)\n",
        "\n",
        "X_test_cat = torch.tensor(X_test_cat, dtype=torch.int64)\n",
        "X_test_num = torch.tensor(X_test_num,dtype=torch.float)\n",
        "y_test = torch.tensor(y_test)\n",
        "print(X_test_cat.shape,X_test_num.shape,y_test.shape)\n",
        "\n",
        "X_eval_cat = torch.tensor(X_eval_cat, dtype=torch.int64)\n",
        "X_eval_num = torch.tensor(X_eval_num,dtype=torch.float)\n",
        "y_eval = torch.tensor(y_eval)\n",
        "print(X_eval_cat.shape,X_eval_num.shape,y_eval.shape)"
      ],
      "metadata": {
        "id": "ZpNUJmPmOC1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa19f11f-09ee-4cdd-dfdb-5c04ee069a64"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7200, 4]) torch.Size([7200, 6]) torch.Size([7200])\n",
            "torch.Size([2000, 4]) torch.Size([2000, 6]) torch.Size([2000])\n",
            "torch.Size([800, 4]) torch.Size([800, 6]) torch.Size([800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class churn_model(nn.Module):\n",
        "\n",
        "  def __init__(self, emb_sizes,cat_count,num_count):\n",
        "    super().__init__()\n",
        "    eml = []\n",
        "    new_cat_size = 0\n",
        "    for col,emb_size in emb_sizes.items():\n",
        "      eml.append(nn.Embedding(emb_size[0],emb_size[1]))\n",
        "      new_cat_size += emb_size[1]\n",
        "    self.embeddings = nn.ModuleList(eml)\n",
        "    self.linears = nn.Sequential()\n",
        "    self.linears.append(nn.Linear(new_cat_size + num_count,32))\n",
        "    self.linears.append(nn.ReLU())\n",
        "    self.linears.append(nn.Linear(32,16))\n",
        "    self.linears.append(nn.ReLU())\n",
        "    self.linears.append(nn.Linear(16,8))\n",
        "    self.linears.append(nn.ReLU())\n",
        "    self.linears.append(nn.Linear(8,4))\n",
        "    self.linears.append(nn.ReLU())\n",
        "    self.linears.append(nn.Linear(4,2))\n",
        "    self.linears.append(nn.Softmax(dim=1))\n",
        "\n",
        "  def forward(self, x_categorical,x_numerical):\n",
        "    embeddings = []\n",
        "    for i,e in enumerate(self.embeddings):\n",
        "      embeddings.append(e(x_categorical[:,i]))\n",
        "    x = torch.cat(embeddings, 1)\n",
        "    x = torch.cat([x,x_numerical],1)\n",
        "    x = self.linears(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "MKl6cDtzQ-NW"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Crossentropy loss\n",
        "\n",
        "def cel(x, y):\n",
        "    log_prob = -1.0 * torch.log(x)\n",
        "    loss = log_prob.gather(1, y.unsqueeze(1))\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "## Testing the CEL\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "batch_size = 5\n",
        "nb_classes = 10\n",
        "x = torch.randn(batch_size, nb_classes, requires_grad=True)\n",
        "y = torch.randint(0, nb_classes, (batch_size,))\n",
        "\n",
        "\n",
        "loss_reference = criterion(x, y)\n",
        "loss = cel(nn.Softmax(dim=1)(x), y)\n",
        "\n",
        "print(loss_reference - loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsRw-mIJb63c",
        "outputId": "9e60e896-07b8-4a9a-9075-3e7061d14236"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0., grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Accuracy\n",
        "\n",
        "def accu(x,y):\n",
        "  index = torch.argmax(x,dim=1)\n",
        "  valids = torch.sum((index == y).float())\n",
        "  shape = x.shape[0]\n",
        "  return torch.div(valids,shape)\n",
        "\n",
        "## Testing accu function\n",
        "\n",
        "batch_size = 5\n",
        "nb_classes = 2\n",
        "x = nn.Softmax(dim=1)(torch.randn(batch_size, nb_classes, requires_grad=True))\n",
        "y = torch.randint(0, nb_classes, (batch_size,))\n",
        "\n",
        "print(x)\n",
        "print(x.shape[0])\n",
        "print(y)\n",
        "\n",
        "res = accu(x,y)\n",
        "print(res)\n",
        "#print(res.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v4tl-oUnY7N",
        "outputId": "13b4b143-f47f-4525-a21d-e799f6890392"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3875, 0.6125],\n",
            "        [0.5510, 0.4490],\n",
            "        [0.9869, 0.0131],\n",
            "        [0.4042, 0.5958],\n",
            "        [0.6600, 0.3400]], grad_fn=<SoftmaxBackward0>)\n",
            "5\n",
            "tensor([1, 1, 1, 0, 0])\n",
            "tensor(0.4000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "epochs = 300\n",
        "batch_size = 8\n",
        "\n",
        "model = churn_model(categorical_embedding_sizes,cat_count,num_count)\n",
        "\n",
        "loss_function = cel\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "for i in range(epochs):\n",
        "    '''\n",
        "    permutation = torch.randperm(X_train_cat.shape[0])\n",
        "\n",
        "    for j in tqdm_notebook(range(0,X_train_cat.shape[0],batch_size)): \n",
        "      # batch data\n",
        "      indices = permutation[i:i+batch_size]\n",
        "      X_batch_cat, X_batch_num, y_batch = X_train_cat[indices], X_train_num[indices], y_train[indices]\n",
        "      # run mini batch\n",
        "      y_batch_pred = model(X_batch_cat, X_batch_num)\n",
        "      single_loss = loss_function(y_batch_pred, y_batch)\n",
        "      # backpropogation\n",
        "      optimizer.zero_grad()\n",
        "      single_loss.backward()\n",
        "      optimizer.step()\n",
        "    '''\n",
        "    # run model\n",
        "    y_pred = model(X_train_cat, X_train_num)\n",
        "    single_loss = loss_function(y_pred, y_train)\n",
        "    # backpropogation\n",
        "    optimizer.zero_grad()\n",
        "    single_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #outputs\n",
        "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
        "    y_eval_pred = model(X_eval_cat,X_eval_num)\n",
        "    eval_loss = loss_function(y_eval_pred,y_eval)\n",
        "    accuracy = accu(y_eval_pred,y_eval)\n",
        "    print(f\"{' ':5} epoch: {i:3} eval loss: {eval_loss:10.4f}\")\n",
        "    print(f\"{' ':12} eval accuracy: {accuracy:10.4}\")\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzr2tSjB5fvp",
        "outputId": "ac26b8a6-78a0-4e05-bda0-864f04ecbcc7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:   0 loss: 0.77101052\n",
            "      epoch:   0 eval loss:     0.7621\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   1 loss: 0.75879395\n",
            "      epoch:   1 eval loss:     0.7506\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   2 loss: 0.74780732\n",
            "      epoch:   2 eval loss:     0.7398\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   3 loss: 0.73760408\n",
            "      epoch:   3 eval loss:     0.7303\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   4 loss: 0.72850853\n",
            "      epoch:   4 eval loss:     0.7227\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   5 loss: 0.72121722\n",
            "      epoch:   5 eval loss:     0.7150\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   6 loss: 0.71393228\n",
            "      epoch:   6 eval loss:     0.7076\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   7 loss: 0.70687950\n",
            "      epoch:   7 eval loss:     0.7002\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   8 loss: 0.69994462\n",
            "      epoch:   8 eval loss:     0.6927\n",
            "             eval accuracy:     0.3812\n",
            "epoch:   9 loss: 0.69280612\n",
            "      epoch:   9 eval loss:     0.6849\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  10 loss: 0.68543279\n",
            "      epoch:  10 eval loss:     0.6765\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  11 loss: 0.67747235\n",
            "      epoch:  11 eval loss:     0.6676\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  12 loss: 0.66900599\n",
            "      epoch:  12 eval loss:     0.6591\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  13 loss: 0.66098416\n",
            "      epoch:  13 eval loss:     0.6521\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  14 loss: 0.65433615\n",
            "      epoch:  14 eval loss:     0.6457\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  15 loss: 0.64829266\n",
            "      epoch:  15 eval loss:     0.6393\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  16 loss: 0.64223123\n",
            "      epoch:  16 eval loss:     0.6338\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  17 loss: 0.63708198\n",
            "      epoch:  17 eval loss:     0.6284\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  18 loss: 0.63202453\n",
            "      epoch:  18 eval loss:     0.6228\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  19 loss: 0.62670666\n",
            "      epoch:  19 eval loss:     0.6167\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  20 loss: 0.62107587\n",
            "      epoch:  20 eval loss:     0.6104\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  21 loss: 0.61507887\n",
            "      epoch:  21 eval loss:     0.6035\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  22 loss: 0.60865116\n",
            "      epoch:  22 eval loss:     0.5958\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  23 loss: 0.60156184\n",
            "      epoch:  23 eval loss:     0.5858\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  24 loss: 0.59211105\n",
            "      epoch:  24 eval loss:     0.5696\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  25 loss: 0.57664388\n",
            "      epoch:  25 eval loss:     0.5497\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  26 loss: 0.55796796\n",
            "      epoch:  26 eval loss:     0.5291\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  27 loss: 0.53898245\n",
            "      epoch:  27 eval loss:     0.5100\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  28 loss: 0.52167475\n",
            "      epoch:  28 eval loss:     0.4948\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  29 loss: 0.50838131\n",
            "      epoch:  29 eval loss:     0.4858\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  30 loss: 0.50146598\n",
            "      epoch:  30 eval loss:     0.4842\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  31 loss: 0.50192595\n",
            "      epoch:  31 eval loss:     0.4888\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  32 loss: 0.50813532\n",
            "      epoch:  32 eval loss:     0.4952\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  33 loss: 0.51550627\n",
            "      epoch:  33 eval loss:     0.4990\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  34 loss: 0.51962340\n",
            "      epoch:  34 eval loss:     0.4988\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  35 loss: 0.51903301\n",
            "      epoch:  35 eval loss:     0.4953\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  36 loss: 0.51470697\n",
            "      epoch:  36 eval loss:     0.4902\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  37 loss: 0.50858742\n",
            "      epoch:  37 eval loss:     0.4853\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  38 loss: 0.50254041\n",
            "      epoch:  38 eval loss:     0.4817\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  39 loss: 0.49783564\n",
            "      epoch:  39 eval loss:     0.4799\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  40 loss: 0.49499086\n",
            "      epoch:  40 eval loss:     0.4797\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  41 loss: 0.49388543\n",
            "      epoch:  41 eval loss:     0.4806\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  42 loss: 0.49400291\n",
            "      epoch:  42 eval loss:     0.4820\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  43 loss: 0.49470562\n",
            "      epoch:  43 eval loss:     0.4833\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  44 loss: 0.49543253\n",
            "      epoch:  44 eval loss:     0.4841\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  45 loss: 0.49579433\n",
            "      epoch:  45 eval loss:     0.4842\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  46 loss: 0.49558568\n",
            "      epoch:  46 eval loss:     0.4837\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  47 loss: 0.49476653\n",
            "      epoch:  47 eval loss:     0.4826\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  48 loss: 0.49341458\n",
            "      epoch:  48 eval loss:     0.4810\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  49 loss: 0.49169409\n",
            "      epoch:  49 eval loss:     0.4793\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  50 loss: 0.48981082\n",
            "      epoch:  50 eval loss:     0.4777\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  51 loss: 0.48798496\n",
            "      epoch:  51 eval loss:     0.4763\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  52 loss: 0.48641831\n",
            "      epoch:  52 eval loss:     0.4754\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  53 loss: 0.48524067\n",
            "      epoch:  53 eval loss:     0.4749\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  54 loss: 0.48450074\n",
            "      epoch:  54 eval loss:     0.4747\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  55 loss: 0.48413610\n",
            "      epoch:  55 eval loss:     0.4749\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  56 loss: 0.48398593\n",
            "      epoch:  56 eval loss:     0.4750\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  57 loss: 0.48383144\n",
            "      epoch:  57 eval loss:     0.4749\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  58 loss: 0.48348162\n",
            "      epoch:  58 eval loss:     0.4746\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  59 loss: 0.48287684\n",
            "      epoch:  59 eval loss:     0.4740\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  60 loss: 0.48203775\n",
            "      epoch:  60 eval loss:     0.4732\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  61 loss: 0.48108751\n",
            "      epoch:  61 eval loss:     0.4724\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  62 loss: 0.48016459\n",
            "      epoch:  62 eval loss:     0.4717\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  63 loss: 0.47936353\n",
            "      epoch:  63 eval loss:     0.4712\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  64 loss: 0.47873160\n",
            "      epoch:  64 eval loss:     0.4707\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  65 loss: 0.47827351\n",
            "      epoch:  65 eval loss:     0.4704\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  66 loss: 0.47793207\n",
            "      epoch:  66 eval loss:     0.4701\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  67 loss: 0.47763923\n",
            "      epoch:  67 eval loss:     0.4698\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  68 loss: 0.47730812\n",
            "      epoch:  68 eval loss:     0.4694\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  69 loss: 0.47686958\n",
            "      epoch:  69 eval loss:     0.4689\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  70 loss: 0.47631934\n",
            "      epoch:  70 eval loss:     0.4682\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  71 loss: 0.47568372\n",
            "      epoch:  71 eval loss:     0.4676\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  72 loss: 0.47501463\n",
            "      epoch:  72 eval loss:     0.4669\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  73 loss: 0.47437891\n",
            "      epoch:  73 eval loss:     0.4663\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  74 loss: 0.47381395\n",
            "      epoch:  74 eval loss:     0.4657\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  75 loss: 0.47333223\n",
            "      epoch:  75 eval loss:     0.4652\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  76 loss: 0.47290656\n",
            "      epoch:  76 eval loss:     0.4647\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  77 loss: 0.47249529\n",
            "      epoch:  77 eval loss:     0.4641\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  78 loss: 0.47204924\n",
            "      epoch:  78 eval loss:     0.4635\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  79 loss: 0.47154289\n",
            "      epoch:  79 eval loss:     0.4628\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  80 loss: 0.47098783\n",
            "      epoch:  80 eval loss:     0.4621\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  81 loss: 0.47040698\n",
            "      epoch:  81 eval loss:     0.4615\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  82 loss: 0.46984044\n",
            "      epoch:  82 eval loss:     0.4608\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  83 loss: 0.46931696\n",
            "      epoch:  83 eval loss:     0.4601\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  84 loss: 0.46883297\n",
            "      epoch:  84 eval loss:     0.4594\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  85 loss: 0.46835208\n",
            "      epoch:  85 eval loss:     0.4586\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  86 loss: 0.46783695\n",
            "      epoch:  86 eval loss:     0.4577\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  87 loss: 0.46728250\n",
            "      epoch:  87 eval loss:     0.4567\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  88 loss: 0.46671680\n",
            "      epoch:  88 eval loss:     0.4557\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  89 loss: 0.46617594\n",
            "      epoch:  89 eval loss:     0.4547\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  90 loss: 0.46567416\n",
            "      epoch:  90 eval loss:     0.4537\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  91 loss: 0.46521834\n",
            "      epoch:  91 eval loss:     0.4529\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  92 loss: 0.46478331\n",
            "      epoch:  92 eval loss:     0.4521\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  93 loss: 0.46435004\n",
            "      epoch:  93 eval loss:     0.4514\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  94 loss: 0.46390542\n",
            "      epoch:  94 eval loss:     0.4508\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  95 loss: 0.46349952\n",
            "      epoch:  95 eval loss:     0.4503\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  96 loss: 0.46310046\n",
            "      epoch:  96 eval loss:     0.4497\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  97 loss: 0.46265861\n",
            "      epoch:  97 eval loss:     0.4491\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  98 loss: 0.46218681\n",
            "      epoch:  98 eval loss:     0.4485\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  99 loss: 0.46168393\n",
            "      epoch:  99 eval loss:     0.4479\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 100 loss: 0.46115288\n",
            "      epoch: 100 eval loss:     0.4473\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 101 loss: 0.46059000\n",
            "      epoch: 101 eval loss:     0.4467\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 102 loss: 0.45999634\n",
            "      epoch: 102 eval loss:     0.4461\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 103 loss: 0.45937273\n",
            "      epoch: 103 eval loss:     0.4455\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 104 loss: 0.45870462\n",
            "      epoch: 104 eval loss:     0.4447\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 105 loss: 0.45797256\n",
            "      epoch: 105 eval loss:     0.4440\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 106 loss: 0.45718881\n",
            "      epoch: 106 eval loss:     0.4432\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 107 loss: 0.45643348\n",
            "      epoch: 107 eval loss:     0.4424\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 108 loss: 0.45576790\n",
            "      epoch: 108 eval loss:     0.4417\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 109 loss: 0.45506313\n",
            "      epoch: 109 eval loss:     0.4408\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 110 loss: 0.45427904\n",
            "      epoch: 110 eval loss:     0.4398\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 111 loss: 0.45347267\n",
            "      epoch: 111 eval loss:     0.4388\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 112 loss: 0.45267659\n",
            "      epoch: 112 eval loss:     0.4379\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 113 loss: 0.45184106\n",
            "      epoch: 113 eval loss:     0.4369\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 114 loss: 0.45091301\n",
            "      epoch: 114 eval loss:     0.4359\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 115 loss: 0.44995245\n",
            "      epoch: 115 eval loss:     0.4349\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 116 loss: 0.44901660\n",
            "      epoch: 116 eval loss:     0.4339\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 117 loss: 0.44801715\n",
            "      epoch: 117 eval loss:     0.4328\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 118 loss: 0.44697449\n",
            "      epoch: 118 eval loss:     0.4318\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 119 loss: 0.44591224\n",
            "      epoch: 119 eval loss:     0.4308\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 120 loss: 0.44484439\n",
            "      epoch: 120 eval loss:     0.4298\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 121 loss: 0.44374353\n",
            "      epoch: 121 eval loss:     0.4287\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 122 loss: 0.44269985\n",
            "      epoch: 122 eval loss:     0.4277\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 123 loss: 0.44164723\n",
            "      epoch: 123 eval loss:     0.4266\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 124 loss: 0.44054690\n",
            "      epoch: 124 eval loss:     0.4254\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 125 loss: 0.43940154\n",
            "      epoch: 125 eval loss:     0.4239\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 126 loss: 0.43821758\n",
            "      epoch: 126 eval loss:     0.4224\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 127 loss: 0.43708310\n",
            "      epoch: 127 eval loss:     0.4212\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 128 loss: 0.43591827\n",
            "      epoch: 128 eval loss:     0.4201\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 129 loss: 0.43478611\n",
            "      epoch: 129 eval loss:     0.4186\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 130 loss: 0.43360057\n",
            "      epoch: 130 eval loss:     0.4173\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 131 loss: 0.43249142\n",
            "      epoch: 131 eval loss:     0.4161\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 132 loss: 0.43136597\n",
            "      epoch: 132 eval loss:     0.4148\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 133 loss: 0.43025303\n",
            "      epoch: 133 eval loss:     0.4135\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 134 loss: 0.42913100\n",
            "      epoch: 134 eval loss:     0.4124\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 135 loss: 0.42801103\n",
            "      epoch: 135 eval loss:     0.4115\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 136 loss: 0.42695042\n",
            "      epoch: 136 eval loss:     0.4105\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 137 loss: 0.42589277\n",
            "      epoch: 137 eval loss:     0.4096\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 138 loss: 0.42483935\n",
            "      epoch: 138 eval loss:     0.4087\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 139 loss: 0.42380244\n",
            "      epoch: 139 eval loss:     0.4077\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 140 loss: 0.42274529\n",
            "      epoch: 140 eval loss:     0.4065\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 141 loss: 0.42172158\n",
            "      epoch: 141 eval loss:     0.4056\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 142 loss: 0.42065239\n",
            "      epoch: 142 eval loss:     0.4044\n",
            "             eval accuracy:      0.805\n",
            "epoch: 143 loss: 0.41955057\n",
            "      epoch: 143 eval loss:     0.4034\n",
            "             eval accuracy:      0.805\n",
            "epoch: 144 loss: 0.41845363\n",
            "      epoch: 144 eval loss:     0.4022\n",
            "             eval accuracy:        0.8\n",
            "epoch: 145 loss: 0.41742519\n",
            "      epoch: 145 eval loss:     0.4011\n",
            "             eval accuracy:     0.7987\n",
            "epoch: 146 loss: 0.41647935\n",
            "      epoch: 146 eval loss:     0.3998\n",
            "             eval accuracy:     0.8012\n",
            "epoch: 147 loss: 0.41557765\n",
            "      epoch: 147 eval loss:     0.3986\n",
            "             eval accuracy:        0.8\n",
            "epoch: 148 loss: 0.41471267\n",
            "      epoch: 148 eval loss:     0.3972\n",
            "             eval accuracy:        0.8\n",
            "epoch: 149 loss: 0.41385302\n",
            "      epoch: 149 eval loss:     0.3959\n",
            "             eval accuracy:     0.7987\n",
            "epoch: 150 loss: 0.41308418\n",
            "      epoch: 150 eval loss:     0.3946\n",
            "             eval accuracy:        0.8\n",
            "epoch: 151 loss: 0.41227895\n",
            "      epoch: 151 eval loss:     0.3935\n",
            "             eval accuracy:     0.8037\n",
            "epoch: 152 loss: 0.41146564\n",
            "      epoch: 152 eval loss:     0.3924\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 153 loss: 0.41069728\n",
            "      epoch: 153 eval loss:     0.3916\n",
            "             eval accuracy:     0.8125\n",
            "epoch: 154 loss: 0.41003412\n",
            "      epoch: 154 eval loss:     0.3910\n",
            "             eval accuracy:     0.8112\n",
            "epoch: 155 loss: 0.40952444\n",
            "      epoch: 155 eval loss:     0.3905\n",
            "             eval accuracy:     0.8138\n",
            "epoch: 156 loss: 0.40894488\n",
            "      epoch: 156 eval loss:     0.3888\n",
            "             eval accuracy:     0.8138\n",
            "epoch: 157 loss: 0.40758833\n",
            "      epoch: 157 eval loss:     0.3881\n",
            "             eval accuracy:     0.8163\n",
            "epoch: 158 loss: 0.40711591\n",
            "      epoch: 158 eval loss:     0.3877\n",
            "             eval accuracy:     0.8138\n",
            "epoch: 159 loss: 0.40652448\n",
            "      epoch: 159 eval loss:     0.3861\n",
            "             eval accuracy:     0.8175\n",
            "epoch: 160 loss: 0.40520537\n",
            "      epoch: 160 eval loss:     0.3858\n",
            "             eval accuracy:     0.8188\n",
            "epoch: 161 loss: 0.40474135\n",
            "      epoch: 161 eval loss:     0.3857\n",
            "             eval accuracy:      0.815\n",
            "epoch: 162 loss: 0.40397978\n",
            "      epoch: 162 eval loss:     0.3847\n",
            "             eval accuracy:      0.815\n",
            "epoch: 163 loss: 0.40284148\n",
            "      epoch: 163 eval loss:     0.3842\n",
            "             eval accuracy:     0.8188\n",
            "epoch: 164 loss: 0.40250102\n",
            "      epoch: 164 eval loss:     0.3834\n",
            "             eval accuracy:     0.8213\n",
            "epoch: 165 loss: 0.40143809\n",
            "      epoch: 165 eval loss:     0.3824\n",
            "             eval accuracy:     0.8213\n",
            "epoch: 166 loss: 0.40051249\n",
            "      epoch: 166 eval loss:     0.3820\n",
            "             eval accuracy:     0.8213\n",
            "epoch: 167 loss: 0.39999330\n",
            "      epoch: 167 eval loss:     0.3813\n",
            "             eval accuracy:      0.825\n",
            "epoch: 168 loss: 0.39885819\n",
            "      epoch: 168 eval loss:     0.3809\n",
            "             eval accuracy:      0.825\n",
            "epoch: 169 loss: 0.39807647\n",
            "      epoch: 169 eval loss:     0.3802\n",
            "             eval accuracy:     0.8213\n",
            "epoch: 170 loss: 0.39741930\n",
            "      epoch: 170 eval loss:     0.3792\n",
            "             eval accuracy:     0.8238\n",
            "epoch: 171 loss: 0.39629215\n",
            "      epoch: 171 eval loss:     0.3786\n",
            "             eval accuracy:     0.8288\n",
            "epoch: 172 loss: 0.39561009\n",
            "      epoch: 172 eval loss:     0.3778\n",
            "             eval accuracy:     0.8238\n",
            "epoch: 173 loss: 0.39473021\n",
            "      epoch: 173 eval loss:     0.3769\n",
            "             eval accuracy:       0.83\n",
            "epoch: 174 loss: 0.39369628\n",
            "      epoch: 174 eval loss:     0.3763\n",
            "             eval accuracy:     0.8313\n",
            "epoch: 175 loss: 0.39300117\n",
            "      epoch: 175 eval loss:     0.3751\n",
            "             eval accuracy:     0.8313\n",
            "epoch: 176 loss: 0.39210919\n",
            "      epoch: 176 eval loss:     0.3741\n",
            "             eval accuracy:     0.8325\n",
            "epoch: 177 loss: 0.39108372\n",
            "      epoch: 177 eval loss:     0.3734\n",
            "             eval accuracy:     0.8375\n",
            "epoch: 178 loss: 0.39027879\n",
            "      epoch: 178 eval loss:     0.3724\n",
            "             eval accuracy:     0.8375\n",
            "epoch: 179 loss: 0.38939780\n",
            "      epoch: 179 eval loss:     0.3716\n",
            "             eval accuracy:      0.835\n",
            "epoch: 180 loss: 0.38833693\n",
            "      epoch: 180 eval loss:     0.3706\n",
            "             eval accuracy:     0.8363\n",
            "epoch: 181 loss: 0.38732782\n",
            "      epoch: 181 eval loss:     0.3696\n",
            "             eval accuracy:     0.8363\n",
            "epoch: 182 loss: 0.38641980\n",
            "      epoch: 182 eval loss:     0.3689\n",
            "             eval accuracy:     0.8338\n",
            "epoch: 183 loss: 0.38551256\n",
            "      epoch: 183 eval loss:     0.3678\n",
            "             eval accuracy:     0.8375\n",
            "epoch: 184 loss: 0.38458064\n",
            "      epoch: 184 eval loss:     0.3673\n",
            "             eval accuracy:     0.8363\n",
            "epoch: 185 loss: 0.38361761\n",
            "      epoch: 185 eval loss:     0.3659\n",
            "             eval accuracy:      0.835\n",
            "epoch: 186 loss: 0.38259706\n",
            "      epoch: 186 eval loss:     0.3651\n",
            "             eval accuracy:       0.84\n",
            "epoch: 187 loss: 0.38141319\n",
            "      epoch: 187 eval loss:     0.3635\n",
            "             eval accuracy:     0.8388\n",
            "epoch: 188 loss: 0.38021782\n",
            "      epoch: 188 eval loss:     0.3626\n",
            "             eval accuracy:     0.8425\n",
            "epoch: 189 loss: 0.37904081\n",
            "      epoch: 189 eval loss:     0.3613\n",
            "             eval accuracy:     0.8438\n",
            "epoch: 190 loss: 0.37790886\n",
            "      epoch: 190 eval loss:     0.3600\n",
            "             eval accuracy:     0.8438\n",
            "epoch: 191 loss: 0.37677416\n",
            "      epoch: 191 eval loss:     0.3593\n",
            "             eval accuracy:     0.8388\n",
            "epoch: 192 loss: 0.37566033\n",
            "      epoch: 192 eval loss:     0.3576\n",
            "             eval accuracy:      0.845\n",
            "epoch: 193 loss: 0.37485734\n",
            "      epoch: 193 eval loss:     0.3594\n",
            "             eval accuracy:     0.8425\n",
            "epoch: 194 loss: 0.37504223\n",
            "      epoch: 194 eval loss:     0.3598\n",
            "             eval accuracy:     0.8438\n",
            "epoch: 195 loss: 0.37863201\n",
            "      epoch: 195 eval loss:     0.3603\n",
            "             eval accuracy:     0.8438\n",
            "epoch: 196 loss: 0.37555218\n",
            "      epoch: 196 eval loss:     0.3532\n",
            "             eval accuracy:     0.8487\n",
            "epoch: 197 loss: 0.37064064\n",
            "      epoch: 197 eval loss:     0.3536\n",
            "             eval accuracy:     0.8438\n",
            "epoch: 198 loss: 0.37330422\n",
            "      epoch: 198 eval loss:     0.3539\n",
            "             eval accuracy:     0.8512\n",
            "epoch: 199 loss: 0.37070450\n",
            "      epoch: 199 eval loss:     0.3510\n",
            "             eval accuracy:       0.85\n",
            "epoch: 200 loss: 0.36864087\n",
            "      epoch: 200 eval loss:     0.3498\n",
            "             eval accuracy:     0.8475\n",
            "epoch: 201 loss: 0.37002417\n",
            "      epoch: 201 eval loss:     0.3488\n",
            "             eval accuracy:     0.8525\n",
            "epoch: 202 loss: 0.36696056\n",
            "      epoch: 202 eval loss:     0.3501\n",
            "             eval accuracy:       0.85\n",
            "epoch: 203 loss: 0.36765280\n",
            "      epoch: 203 eval loss:     0.3462\n",
            "             eval accuracy:     0.8512\n",
            "epoch: 204 loss: 0.36727545\n",
            "      epoch: 204 eval loss:     0.3447\n",
            "             eval accuracy:     0.8525\n",
            "epoch: 205 loss: 0.36474553\n",
            "      epoch: 205 eval loss:     0.3480\n",
            "             eval accuracy:     0.8562\n",
            "epoch: 206 loss: 0.36613932\n",
            "      epoch: 206 eval loss:     0.3430\n",
            "             eval accuracy:     0.8537\n",
            "epoch: 207 loss: 0.36403775\n",
            "      epoch: 207 eval loss:     0.3423\n",
            "             eval accuracy:     0.8525\n",
            "epoch: 208 loss: 0.36324388\n",
            "      epoch: 208 eval loss:     0.3447\n",
            "             eval accuracy:     0.8562\n",
            "epoch: 209 loss: 0.36362433\n",
            "      epoch: 209 eval loss:     0.3407\n",
            "             eval accuracy:     0.8562\n",
            "epoch: 210 loss: 0.36144102\n",
            "      epoch: 210 eval loss:     0.3406\n",
            "             eval accuracy:     0.8537\n",
            "epoch: 211 loss: 0.36158350\n",
            "      epoch: 211 eval loss:     0.3416\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 212 loss: 0.36108211\n",
            "      epoch: 212 eval loss:     0.3388\n",
            "             eval accuracy:      0.855\n",
            "epoch: 213 loss: 0.35951370\n",
            "      epoch: 213 eval loss:     0.3388\n",
            "             eval accuracy:     0.8537\n",
            "epoch: 214 loss: 0.35990265\n",
            "      epoch: 214 eval loss:     0.3391\n",
            "             eval accuracy:     0.8575\n",
            "epoch: 215 loss: 0.35908297\n",
            "      epoch: 215 eval loss:     0.3374\n",
            "             eval accuracy:     0.8575\n",
            "epoch: 216 loss: 0.35793221\n",
            "      epoch: 216 eval loss:     0.3371\n",
            "             eval accuracy:      0.855\n",
            "epoch: 217 loss: 0.35832167\n",
            "      epoch: 217 eval loss:     0.3369\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 218 loss: 0.35721159\n",
            "      epoch: 218 eval loss:     0.3358\n",
            "             eval accuracy:       0.86\n",
            "epoch: 219 loss: 0.35647234\n",
            "      epoch: 219 eval loss:     0.3352\n",
            "             eval accuracy:     0.8575\n",
            "epoch: 220 loss: 0.35662305\n",
            "      epoch: 220 eval loss:     0.3350\n",
            "             eval accuracy:     0.8575\n",
            "epoch: 221 loss: 0.35579684\n",
            "      epoch: 221 eval loss:     0.3340\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 222 loss: 0.35507613\n",
            "      epoch: 222 eval loss:     0.3335\n",
            "             eval accuracy:       0.86\n",
            "epoch: 223 loss: 0.35506442\n",
            "      epoch: 223 eval loss:     0.3336\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 224 loss: 0.35461420\n",
            "      epoch: 224 eval loss:     0.3325\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 225 loss: 0.35389695\n",
            "      epoch: 225 eval loss:     0.3321\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 226 loss: 0.35353211\n",
            "      epoch: 226 eval loss:     0.3323\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 227 loss: 0.35353407\n",
            "      epoch: 227 eval loss:     0.3315\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 228 loss: 0.35324407\n",
            "      epoch: 228 eval loss:     0.3312\n",
            "             eval accuracy:      0.865\n",
            "epoch: 229 loss: 0.35248709\n",
            "      epoch: 229 eval loss:     0.3306\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 230 loss: 0.35197851\n",
            "      epoch: 230 eval loss:     0.3302\n",
            "             eval accuracy:       0.86\n",
            "epoch: 231 loss: 0.35171491\n",
            "      epoch: 231 eval loss:     0.3306\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 232 loss: 0.35151199\n",
            "      epoch: 232 eval loss:     0.3301\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 233 loss: 0.35124853\n",
            "      epoch: 233 eval loss:     0.3304\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 234 loss: 0.35090041\n",
            "      epoch: 234 eval loss:     0.3298\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 235 loss: 0.35057643\n",
            "      epoch: 235 eval loss:     0.3294\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 236 loss: 0.35033682\n",
            "      epoch: 236 eval loss:     0.3293\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 237 loss: 0.35016376\n",
            "      epoch: 237 eval loss:     0.3288\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 238 loss: 0.35005674\n",
            "      epoch: 238 eval loss:     0.3294\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 239 loss: 0.35003677\n",
            "      epoch: 239 eval loss:     0.3292\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 240 loss: 0.35040170\n",
            "      epoch: 240 eval loss:     0.3309\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 241 loss: 0.35099217\n",
            "      epoch: 241 eval loss:     0.3308\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 242 loss: 0.35197434\n",
            "      epoch: 242 eval loss:     0.3313\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 243 loss: 0.35126576\n",
            "      epoch: 243 eval loss:     0.3287\n",
            "             eval accuracy:      0.865\n",
            "epoch: 244 loss: 0.34982499\n",
            "      epoch: 244 eval loss:     0.3277\n",
            "             eval accuracy:      0.865\n",
            "epoch: 245 loss: 0.34868333\n",
            "      epoch: 245 eval loss:     0.3286\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 246 loss: 0.34934217\n",
            "      epoch: 246 eval loss:     0.3293\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 247 loss: 0.35077590\n",
            "      epoch: 247 eval loss:     0.3294\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 248 loss: 0.34976074\n",
            "      epoch: 248 eval loss:     0.3274\n",
            "             eval accuracy:      0.865\n",
            "epoch: 249 loss: 0.34836406\n",
            "      epoch: 249 eval loss:     0.3273\n",
            "             eval accuracy:      0.865\n",
            "epoch: 250 loss: 0.34823143\n",
            "      epoch: 250 eval loss:     0.3289\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 251 loss: 0.34904227\n",
            "      epoch: 251 eval loss:     0.3283\n",
            "             eval accuracy:      0.865\n",
            "epoch: 252 loss: 0.34915045\n",
            "      epoch: 252 eval loss:     0.3274\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 253 loss: 0.34762055\n",
            "      epoch: 253 eval loss:     0.3282\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 254 loss: 0.34804505\n",
            "      epoch: 254 eval loss:     0.3288\n",
            "             eval accuracy:      0.865\n",
            "epoch: 255 loss: 0.34913370\n",
            "      epoch: 255 eval loss:     0.3283\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 256 loss: 0.34776303\n",
            "      epoch: 256 eval loss:     0.3274\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 257 loss: 0.34709162\n",
            "      epoch: 257 eval loss:     0.3274\n",
            "             eval accuracy:      0.865\n",
            "epoch: 258 loss: 0.34752795\n",
            "      epoch: 258 eval loss:     0.3278\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 259 loss: 0.34722513\n",
            "      epoch: 259 eval loss:     0.3271\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 260 loss: 0.34675491\n",
            "      epoch: 260 eval loss:     0.3271\n",
            "             eval accuracy:      0.865\n",
            "epoch: 261 loss: 0.34682235\n",
            "      epoch: 261 eval loss:     0.3275\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 262 loss: 0.34676272\n",
            "      epoch: 262 eval loss:     0.3270\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 263 loss: 0.34651214\n",
            "      epoch: 263 eval loss:     0.3270\n",
            "             eval accuracy:      0.865\n",
            "epoch: 264 loss: 0.34634635\n",
            "      epoch: 264 eval loss:     0.3274\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 265 loss: 0.34638059\n",
            "      epoch: 265 eval loss:     0.3271\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 266 loss: 0.34625384\n",
            "      epoch: 266 eval loss:     0.3272\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 267 loss: 0.34602216\n",
            "      epoch: 267 eval loss:     0.3275\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 268 loss: 0.34604105\n",
            "      epoch: 268 eval loss:     0.3271\n",
            "             eval accuracy:      0.865\n",
            "epoch: 269 loss: 0.34606487\n",
            "      epoch: 269 eval loss:     0.3272\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 270 loss: 0.34577474\n",
            "      epoch: 270 eval loss:     0.3271\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 271 loss: 0.34568465\n",
            "      epoch: 271 eval loss:     0.3270\n",
            "             eval accuracy:      0.865\n",
            "epoch: 272 loss: 0.34574875\n",
            "      epoch: 272 eval loss:     0.3273\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 273 loss: 0.34563085\n",
            "      epoch: 273 eval loss:     0.3268\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 274 loss: 0.34538427\n",
            "      epoch: 274 eval loss:     0.3268\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 275 loss: 0.34533736\n",
            "      epoch: 275 eval loss:     0.3273\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 276 loss: 0.34540057\n",
            "      epoch: 276 eval loss:     0.3270\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 277 loss: 0.34535494\n",
            "      epoch: 277 eval loss:     0.3272\n",
            "             eval accuracy:      0.865\n",
            "epoch: 278 loss: 0.34526947\n",
            "      epoch: 278 eval loss:     0.3267\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 279 loss: 0.34511042\n",
            "      epoch: 279 eval loss:     0.3267\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 280 loss: 0.34492093\n",
            "      epoch: 280 eval loss:     0.3266\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 281 loss: 0.34480944\n",
            "      epoch: 281 eval loss:     0.3266\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 282 loss: 0.34476909\n",
            "      epoch: 282 eval loss:     0.3268\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 283 loss: 0.34477720\n",
            "      epoch: 283 eval loss:     0.3264\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 284 loss: 0.34478197\n",
            "      epoch: 284 eval loss:     0.3267\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 285 loss: 0.34470242\n",
            "      epoch: 285 eval loss:     0.3264\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 286 loss: 0.34460947\n",
            "      epoch: 286 eval loss:     0.3266\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 287 loss: 0.34447560\n",
            "      epoch: 287 eval loss:     0.3262\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 288 loss: 0.34432763\n",
            "      epoch: 288 eval loss:     0.3260\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 289 loss: 0.34422973\n",
            "      epoch: 289 eval loss:     0.3260\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 290 loss: 0.34417093\n",
            "      epoch: 290 eval loss:     0.3260\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 291 loss: 0.34414914\n",
            "      epoch: 291 eval loss:     0.3262\n",
            "             eval accuracy:       0.86\n",
            "epoch: 292 loss: 0.34411764\n",
            "      epoch: 292 eval loss:     0.3259\n",
            "             eval accuracy:      0.865\n",
            "epoch: 293 loss: 0.34412012\n",
            "      epoch: 293 eval loss:     0.3261\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 294 loss: 0.34404662\n",
            "      epoch: 294 eval loss:     0.3258\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 295 loss: 0.34390998\n",
            "      epoch: 295 eval loss:     0.3261\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 296 loss: 0.34376189\n",
            "      epoch: 296 eval loss:     0.3262\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 297 loss: 0.34366429\n",
            "      epoch: 297 eval loss:     0.3262\n",
            "             eval accuracy:      0.865\n",
            "epoch: 298 loss: 0.34361067\n",
            "      epoch: 298 eval loss:     0.3264\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 299 loss: 0.34359375\n",
            "      epoch: 299 eval loss:     0.3262\n",
            "             eval accuracy:     0.8625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Confusion matrix and f1 score\n",
        "import scipy\n",
        "\n",
        "def confusion_matrix(x,y,num_classes = 2):\n",
        "  x = x.detach().numpy()\n",
        "  y = y.detach().numpy()\n",
        "  x = np.argmax(x,axis=1)\n",
        "  data = np.ones(y.shape[0], dtype=np.int64)\n",
        "  ind = np.logical_and(x < num_classes, y < num_classes)\n",
        "  if not np.all(ind):\n",
        "      x = x[ind]\n",
        "      y = y[ind]\n",
        "      data = data[ind]\n",
        "\n",
        "\n",
        "  cm = scipy.sparse.coo_matrix((data,(x,y)),shape=(num_classes,num_classes),dtype=np.int64).toarray()\n",
        "  cm = np.nan_to_num(cm)\n",
        "\n",
        "  return cm\n",
        "\n",
        "## Confusion matrix test\n",
        "x = torch.tensor(np.random.randint(2, size=(5,2)))\n",
        "y = torch.tensor(np.random.randint(2, size=5))\n",
        "\n",
        "print(x,y)\n",
        "print(confusion_matrix(x,y))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqTzNL6tzJgi",
        "outputId": "de8dd172-7329-4bdb-9b32-ea16e659360b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [1, 0],\n",
            "        [0, 0],\n",
            "        [0, 1],\n",
            "        [0, 0]]) tensor([1, 0, 0, 1, 1])\n",
            "[[2 1]\n",
            " [0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model performance on Test data\n",
        "\n",
        "y_test_pred = model(X_test_cat,X_test_num)\n",
        "test_accuracy = accu(y_test_pred,y_test)\n",
        "test_cm = confusion_matrix(y_test_pred,y_test)\n",
        "\n",
        "print(f\"Test Accuracy:{test_accuracy:2.4}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(test_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUEv3ZdMXTRd",
        "outputId": "616dc933-8f80-41fe-ac6a-4af6ff2e9692"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.8575\n",
            "Confusion Matrix:\n",
            "[[1551  229]\n",
            " [  56  164]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Divided Input"
      ],
      "metadata": {
        "id": "tk7xrJODtm9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#X_train_cat = [np.reshape(X_train[col].values,(X_train[col].shape[0],1)) for col in categorical_columns]\n",
        "X_train_cat = [X_train[col].values for col in categorical_columns]\n",
        "X_train_num = np.stack([X_train[col].values for col in numerical_columns],1)\n",
        "X_train = X_train_cat + [X_train_num]\n",
        "y_train = np.reshape(y_train.values,y_train.shape[0])\n",
        "print([ten.shape for ten in X_train],y_train.shape)\n",
        "\n",
        "#X_test_cat = [np.reshape(X_test[col].values,(X_test[col].shape[0],1)) for col in categorical_columns]\n",
        "X_test_cat = [X_test[col].values for col in categorical_columns]\n",
        "X_test_num = np.stack([X_test[col].values for col in numerical_columns],1)\n",
        "X_test = X_test_cat + [X_test_num]\n",
        "y_test = np.reshape(y_test.values,y_test.shape[0])\n",
        "print([ten.shape for ten in X_test],y_test.shape)\n",
        "\n",
        "#X_eval_cat = [np.reshape(X_eval[col].values,(X_eval[col].shape[0],1)) for col in categorical_columns]\n",
        "X_eval_cat = [X_eval[col].values for col in categorical_columns]\n",
        "X_eval_num = np.stack([X_eval[col].values for col in numerical_columns],1)\n",
        "X_eval = X_eval_cat + [X_eval_num]\n",
        "y_eval = np.reshape(y_eval.values,y_eval.shape[0])\n",
        "print([ten.shape for ten in X_eval],y_eval.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTo7NUFttpVx",
        "outputId": "6ea05ad9-145f-4dbf-91cd-f8be72362eff"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(7200,), (7200,), (7200,), (7200,), (7200, 6)] (7200,)\n",
            "[(2000,), (2000,), (2000,), (2000,), (2000, 6)] (2000,)\n",
            "[(800,), (800,), (800,), (800,), (800, 6)] (800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Section"
      ],
      "metadata": {
        "id": "19Xypf95zNRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tensorflow tensor construction\n",
        "import tensorflow as tf\n",
        "\n",
        "X_train = [tf.convert_to_tensor(ten,dtype = (tf.int64 if i < 4 else tf.float64)) for i,ten in enumerate(X_train)]\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "\n",
        "X_test = [tf.convert_to_tensor(ten,dtype = (tf.int64 if i < 4 else tf.float64)) for i,ten in enumerate(X_test)]\n",
        "y_test = tf.convert_to_tensor(y_test)\n",
        "\n",
        "X_eval = [tf.convert_to_tensor(ten,dtype = (tf.int64 if i < 4 else tf.float64)) for i,ten in enumerate(X_eval)]\n",
        "X_eval_num = tf.convert_to_tensor(X_eval_num,dtype = tf.float64)\n",
        "y_eval = tf.convert_to_tensor(y_eval)"
      ],
      "metadata": {
        "id": "_yQ3FzUow7Lt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_layer = [tf.keras.Input(shape=(1 if len(ten.shape) == 1 else ten.shape[1])) for ten in X_train]\n",
        "\n",
        "emb_layers = []\n",
        "for i,col in enumerate(categorical_columns):\n",
        "  em_size = categorical_embedding_sizes[col]\n",
        "  emb_layer = tf.keras.layers.Embedding(em_size[0],em_size[1])(in_layer[i])\n",
        "  emb_layers.append(tf.keras.layers.Flatten()(emb_layer))\n",
        "merge = tf.keras.layers.Concatenate(axis=1)(emb_layers + in_layer[-1:])\n",
        "x2 = tf.keras.layers.Dense(3,activation='relu')(merge)\n",
        "x7 = tf.keras.layers.Dense(2,activation='softmax')(x2)\n",
        "out_layer = x7\n",
        "model2 = tf.keras.Model(inputs=in_layer, outputs=out_layer)\n",
        "print(model2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS_AQ2zS17Cz",
        "outputId": "71557881-6844-479e-84ca-ab941c963b68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_22 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_23 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_24 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_16 (Embedding)       (None, 1, 2)         6           ['input_21[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_17 (Embedding)       (None, 1, 1)         2           ['input_22[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_18 (Embedding)       (None, 1, 1)         2           ['input_23[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_19 (Embedding)       (None, 1, 1)         2           ['input_24[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_16 (Flatten)           (None, 2)            0           ['embedding_16[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_17 (Flatten)           (None, 1)            0           ['embedding_17[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_18 (Flatten)           (None, 1)            0           ['embedding_18[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_19 (Flatten)           (None, 1)            0           ['embedding_19[0][0]']           \n",
            "                                                                                                  \n",
            " input_25 (InputLayer)          [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 11)           0           ['flatten_16[0][0]',             \n",
            "                                                                  'flatten_17[0][0]',             \n",
            "                                                                  'flatten_18[0][0]',             \n",
            "                                                                  'flatten_19[0][0]',             \n",
            "                                                                  'input_25[0][0]']               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 3)            36          ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 2)            8           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 56\n",
            "Trainable params: 56\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test input/output shapes\n",
        "print('input:')\n",
        "x = [ten[:12] for ten in X_eval]\n",
        "print(x)\n",
        "print('output:')\n",
        "print(model2(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCm-y8Mf22B4",
        "outputId": "4a2eeee4-5a80-472e-d30f-c5587f586809"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:\n",
            "[<tf.Tensor: shape=(12,), dtype=int64, numpy=array([0, 1, 2, 0, 2, 1, 0, 2, 0, 1, 0, 0])>, <tf.Tensor: shape=(12,), dtype=int64, numpy=array([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1])>, <tf.Tensor: shape=(12,), dtype=int64, numpy=array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1])>, <tf.Tensor: shape=(12,), dtype=int64, numpy=array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1])>, <tf.Tensor: shape=(12, 6), dtype=float64, numpy=\n",
            "array([[0.902     , 0.18918919, 0.4       , 0.29960587, 0.        ,\n",
            "        0.18945269],\n",
            "       [0.832     , 0.13513514, 0.4       , 0.36148852, 0.        ,\n",
            "        0.10793841],\n",
            "       [0.956     , 0.13513514, 0.8       , 0.53713781, 0.        ,\n",
            "        0.39675934],\n",
            "       [0.896     , 0.24324324, 0.1       , 0.        , 0.33333333,\n",
            "        0.79523855],\n",
            "       [0.522     , 0.21621622, 0.4       , 0.        , 0.33333333,\n",
            "        0.85477663],\n",
            "       [0.502     , 0.48648649, 0.1       , 0.52228365, 0.33333333,\n",
            "        0.99834494],\n",
            "       [0.696     , 0.52702703, 0.6       , 0.54335001, 0.33333333,\n",
            "        0.36272309],\n",
            "       [0.828     , 0.2027027 , 0.9       , 0.67343984, 0.        ,\n",
            "        0.59491146],\n",
            "       [0.444     , 0.2027027 , 0.5       , 0.        , 0.        ,\n",
            "        0.20565699],\n",
            "       [0.58      , 0.75675676, 0.2       , 0.46552865, 0.        ,\n",
            "        0.17061054],\n",
            "       [0.548     , 0.27027027, 0.3       , 0.        , 0.33333333,\n",
            "        0.8183545 ],\n",
            "       [0.864     , 0.18918919, 0.9       , 0.        , 0.        ,\n",
            "        0.43781876]])>]\n",
            "output:\n",
            "tf.Tensor(\n",
            "[[0.5        0.5       ]\n",
            " [0.5        0.5       ]\n",
            " [0.5        0.5       ]\n",
            " [0.4950228  0.5049772 ]\n",
            " [0.4804167  0.5195833 ]\n",
            " [0.49921754 0.5007825 ]\n",
            " [0.49296686 0.5070331 ]\n",
            " [0.5        0.5       ]\n",
            " [0.49101433 0.5089856 ]\n",
            " [0.5        0.5       ]\n",
            " [0.4897689  0.51023114]\n",
            " [0.5        0.5       ]], shape=(12, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer=tf.keras.optimizers.Adam(lr = 0.005),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "          metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],)\n",
        "model2.fit(X_train, y_train, epochs=50, batch_size=8)#,validation_data=(X_eval, y_eval))\n",
        "_, accuracy = model2.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO-Elbl9CXEj",
        "outputId": "77d38f35-4e2d-439a-a89e-f9b122c311c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900/900 [==============================] - 2s 2ms/step - loss: 0.4808 - acc: 0.7983\n",
            "Epoch 2/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3931 - acc: 0.8331\n",
            "Epoch 3/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3779 - acc: 0.8390\n",
            "Epoch 4/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3763 - acc: 0.8450\n",
            "Epoch 5/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3745 - acc: 0.8431\n",
            "Epoch 6/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3722 - acc: 0.8400\n",
            "Epoch 7/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3742 - acc: 0.8417\n",
            "Epoch 8/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3739 - acc: 0.8421\n",
            "Epoch 9/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3722 - acc: 0.8411\n",
            "Epoch 10/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3704 - acc: 0.8431\n",
            "Epoch 11/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3668 - acc: 0.8450\n",
            "Epoch 12/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3627 - acc: 0.8501\n",
            "Epoch 13/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3626 - acc: 0.8483\n",
            "Epoch 14/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3593 - acc: 0.8493\n",
            "Epoch 15/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3585 - acc: 0.8500\n",
            "Epoch 16/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3582 - acc: 0.8494\n",
            "Epoch 17/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3586 - acc: 0.8485\n",
            "Epoch 18/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3574 - acc: 0.8503\n",
            "Epoch 19/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3576 - acc: 0.8531\n",
            "Epoch 20/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3566 - acc: 0.8540\n",
            "Epoch 21/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3572 - acc: 0.8519\n",
            "Epoch 22/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3567 - acc: 0.8485\n",
            "Epoch 23/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3560 - acc: 0.8533\n",
            "Epoch 24/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3544 - acc: 0.8493\n",
            "Epoch 25/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3533 - acc: 0.8547\n",
            "Epoch 26/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3526 - acc: 0.8550\n",
            "Epoch 27/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3539 - acc: 0.8525\n",
            "Epoch 28/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3541 - acc: 0.8556\n",
            "Epoch 29/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3532 - acc: 0.8506\n",
            "Epoch 30/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3532 - acc: 0.8533\n",
            "Epoch 31/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3519 - acc: 0.8553\n",
            "Epoch 32/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3532 - acc: 0.8529\n",
            "Epoch 33/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3529 - acc: 0.8562\n",
            "Epoch 34/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3522 - acc: 0.8537\n",
            "Epoch 35/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3525 - acc: 0.8537\n",
            "Epoch 36/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3520 - acc: 0.8547\n",
            "Epoch 37/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3519 - acc: 0.8531\n",
            "Epoch 38/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3517 - acc: 0.8575\n",
            "Epoch 39/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3510 - acc: 0.8556\n",
            "Epoch 40/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3522 - acc: 0.8540\n",
            "Epoch 41/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3515 - acc: 0.8549\n",
            "Epoch 42/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3523 - acc: 0.8522\n",
            "Epoch 43/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3506 - acc: 0.8554\n",
            "Epoch 44/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3505 - acc: 0.8583\n",
            "Epoch 45/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3521 - acc: 0.8568\n",
            "Epoch 46/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3529 - acc: 0.8521\n",
            "Epoch 47/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3505 - acc: 0.8542\n",
            "Epoch 48/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3498 - acc: 0.8574\n",
            "Epoch 49/50\n",
            "900/900 [==============================] - 2s 2ms/step - loss: 0.3493 - acc: 0.8524\n",
            "Epoch 50/50\n",
            "900/900 [==============================] - 1s 2ms/step - loss: 0.3501 - acc: 0.8569\n",
            "Accuracy: 86.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = model2.evaluate(X_train, y_train)\n",
        "_, test_acc = model2.evaluate(X_test, y_test)\n",
        "y_pred = [list(x).index(max(x)) for x in model2.predict(X_test)]\n",
        "\n",
        "print('First Model Acc:')\n",
        "print(\"train acc\", train_acc)\n",
        "print(\" test acc\", test_acc)\n",
        "print(tf.math.confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTC7WtxiYt2m",
        "outputId": "0bdf117c-a873-4b81-9f84-c6527eecf875"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 1s 2ms/step - loss: 0.3442 - acc: 0.8561\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3434 - acc: 0.8625\n",
            "First Model Acc:\n",
            "train acc 0.8561111092567444\n",
            " test acc 0.862500011920929\n",
            "tf.Tensor(\n",
            "[[1558   49]\n",
            " [ 226  167]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Section"
      ],
      "metadata": {
        "id": "_PDuUyuqJFJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X_train = [torch.tensor(ten, dtype=(torch.int64 if i < 4 else torch.float)) for i,ten in enumerate(X_train)]\n",
        "y_train = torch.tensor(y_train)\n",
        "print([ten.shape for ten in X_train],y_train.shape)\n",
        "\n",
        "X_test = [torch.tensor(ten, dtype=(torch.int64 if i < 4 else torch.float)) for i,ten in enumerate(X_test)]\n",
        "y_test = torch.tensor(y_test)\n",
        "print([ten.shape for ten in X_test],y_test.shape)\n",
        "\n",
        "X_eval = [torch.tensor(ten, dtype=(torch.int64 if i < 4 else torch.float)) for i,ten in enumerate(X_eval)]\n",
        "y_eval = torch.tensor(y_eval)\n",
        "print([ten.shape for ten in X_eval],y_eval.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwJZqBi2JH-u",
        "outputId": "f39bce56-eec6-40da-d862-3d4e7796b4b3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.Size([7200]), torch.Size([7200]), torch.Size([7200]), torch.Size([7200]), torch.Size([7200, 6])] torch.Size([7200])\n",
            "[torch.Size([2000]), torch.Size([2000]), torch.Size([2000]), torch.Size([2000]), torch.Size([2000, 6])] torch.Size([2000])\n",
            "[torch.Size([800]), torch.Size([800]), torch.Size([800]), torch.Size([800]), torch.Size([800, 6])] torch.Size([800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class churn_model(nn.Module):\n",
        "\n",
        "  def __init__(self, emb_sizes,cat_count,num_count):\n",
        "    super().__init__()\n",
        "    eml = []\n",
        "    new_cat_size = 0\n",
        "    for col,emb_size in emb_sizes.items():\n",
        "      eml.append(nn.Embedding(emb_size[0],emb_size[1]))\n",
        "      new_cat_size += emb_size[1]\n",
        "    self.embeddings = nn.ModuleList(eml)\n",
        "    self.linears = nn.Sequential()\n",
        "    self.linears.append(nn.Linear(new_cat_size + num_count,32))\n",
        "    self.linears.append(nn.ReLU())\n",
        "    self.linears.append(nn.Linear(32,16))\n",
        "    self.linears.append(nn.ReLU())\n",
        "    self.linears.append(nn.Linear(16,8))\n",
        "    self.linears.append(nn.ReLU())\n",
        "    #self.linears.append(nn.Linear(8,4))\n",
        "    #self.linears.append(nn.ReLU())\n",
        "    self.linears.append(nn.Linear(8,2))\n",
        "    self.linears.append(nn.Softmax(dim=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    embeddings = []\n",
        "    for i,e in enumerate(self.embeddings):\n",
        "      embeddings.append(e(x[i]))\n",
        "    x = torch.cat(embeddings + x[len(self.embeddings):], 1)\n",
        "    x = self.linears(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dsH5j9t-XVS3"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test input/output shapes\n",
        "print('input:')\n",
        "x = [ten[:1] for ten in X_eval]\n",
        "print(x)\n",
        "print('output:')\n",
        "model2 = churn_model(categorical_embedding_sizes,cat_count,num_count)\n",
        "print(model2(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THL6Y6P8tD63",
        "outputId": "55fee301-82b1-4c07-d2e2-1dd0d01dfeb9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:\n",
            "[tensor([0]), tensor([0]), tensor([1]), tensor([1]), tensor([[0.9020, 0.1892, 0.4000, 0.2996, 0.0000, 0.1895]])]\n",
            "output:\n",
            "tensor([[0.4890, 0.5110]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Crossentropy loss\n",
        "\n",
        "def cel(x, y):\n",
        "    log_prob = -1.0 * torch.log(x)\n",
        "    loss = log_prob.gather(1, y.unsqueeze(1))\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "## Testing the CEL\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "batch_size = 5\n",
        "nb_classes = 10\n",
        "x = torch.randn(batch_size, nb_classes, requires_grad=True)\n",
        "y = torch.randint(0, nb_classes, (batch_size,))\n",
        "\n",
        "\n",
        "loss_reference = criterion(x, y)\n",
        "loss = cel(nn.Softmax(dim=1)(x), y)\n",
        "\n",
        "print(loss_reference - loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcILxm5DZd7U",
        "outputId": "6bc04794-78d1-439c-e5b9-6ea2ed1c7470"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3842e-07, grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Accuracy\n",
        "\n",
        "def accu(x,y):\n",
        "  index = torch.argmax(x,dim=1)\n",
        "  valids = torch.sum((index == y).float())\n",
        "  shape = x.shape[0]\n",
        "  return torch.div(valids,shape)\n",
        "\n",
        "## Testing accu function\n",
        "\n",
        "batch_size = 5\n",
        "nb_classes = 2\n",
        "x = nn.Softmax(dim=1)(torch.randn(batch_size, nb_classes, requires_grad=True))\n",
        "y = torch.randint(0, nb_classes, (batch_size,))\n",
        "\n",
        "print(x)\n",
        "print(x.shape[0])\n",
        "print(y)\n",
        "\n",
        "res = accu(x,y)\n",
        "print(res)\n",
        "#print(res.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atTCrH1nYRCS",
        "outputId": "40ced4c2-13bb-4ae3-fd6a-021b84c434ac"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4309, 0.5691],\n",
            "        [0.6378, 0.3622],\n",
            "        [0.1065, 0.8935],\n",
            "        [0.3350, 0.6650],\n",
            "        [0.7413, 0.2587]], grad_fn=<SoftmaxBackward0>)\n",
            "5\n",
            "tensor([1, 0, 1, 1, 1])\n",
            "tensor(0.8000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "epochs = 300\n",
        "batch_size = 8\n",
        "\n",
        "model = churn_model(categorical_embedding_sizes,cat_count,num_count)\n",
        "\n",
        "loss_function = cel\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "for i in range(epochs):\n",
        "    '''\n",
        "    permutation = torch.randperm(X_train_cat.shape[0])\n",
        "\n",
        "    for j in tqdm_notebook(range(0,X_train_cat.shape[0],batch_size)): \n",
        "      # batch data\n",
        "      indices = permutation[i:i+batch_size]\n",
        "      X_batch_cat, X_batch_num, y_batch = X_train_cat[indices], X_train_num[indices], y_train[indices]\n",
        "      # run mini batch\n",
        "      y_batch_pred = model(X_batch_cat, X_batch_num)\n",
        "      single_loss = loss_function(y_batch_pred, y_batch)\n",
        "      # backpropogation\n",
        "      optimizer.zero_grad()\n",
        "      single_loss.backward()\n",
        "      optimizer.step()\n",
        "    '''\n",
        "    # run model\n",
        "    y_pred = model(X_train)\n",
        "    single_loss = loss_function(y_pred, y_train)\n",
        "    # backpropogation\n",
        "    optimizer.zero_grad()\n",
        "    single_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #outputs\n",
        "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
        "    y_eval_pred = model(X_eval)\n",
        "    eval_loss = loss_function(y_eval_pred,y_eval)\n",
        "    accuracy = accu(y_eval_pred,y_eval)\n",
        "    print(f\"{' ':5} epoch: {i:3} eval loss: {eval_loss:10.4f}\")\n",
        "    print(f\"{' ':12} eval accuracy: {accuracy:10.4}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcJ64DkAYUtB",
        "outputId": "eb90b66a-068d-49b5-b3ab-50298e371f66"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:   0 loss: 0.75785184\n",
            "      epoch:   0 eval loss:     0.7474\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   1 loss: 0.74482232\n",
            "      epoch:   1 eval loss:     0.7364\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   2 loss: 0.73429126\n",
            "      epoch:   2 eval loss:     0.7261\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   3 loss: 0.72456557\n",
            "      epoch:   3 eval loss:     0.7160\n",
            "             eval accuracy:     0.1912\n",
            "epoch:   4 loss: 0.71508974\n",
            "      epoch:   4 eval loss:     0.7052\n",
            "             eval accuracy:     0.2013\n",
            "epoch:   5 loss: 0.70490259\n",
            "      epoch:   5 eval loss:     0.6933\n",
            "             eval accuracy:     0.4613\n",
            "epoch:   6 loss: 0.69370401\n",
            "      epoch:   6 eval loss:     0.6803\n",
            "             eval accuracy:     0.8012\n",
            "epoch:   7 loss: 0.68148059\n",
            "      epoch:   7 eval loss:     0.6660\n",
            "             eval accuracy:     0.8087\n",
            "epoch:   8 loss: 0.66802055\n",
            "      epoch:   8 eval loss:     0.6506\n",
            "             eval accuracy:     0.8087\n",
            "epoch:   9 loss: 0.65346301\n",
            "      epoch:   9 eval loss:     0.6341\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  10 loss: 0.63803476\n",
            "      epoch:  10 eval loss:     0.6166\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  11 loss: 0.62174493\n",
            "      epoch:  11 eval loss:     0.5982\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  12 loss: 0.60460818\n",
            "      epoch:  12 eval loss:     0.5790\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  13 loss: 0.58684921\n",
            "      epoch:  13 eval loss:     0.5596\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  14 loss: 0.56908542\n",
            "      epoch:  14 eval loss:     0.5408\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  15 loss: 0.55216998\n",
            "      epoch:  15 eval loss:     0.5239\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  16 loss: 0.53729707\n",
            "      epoch:  16 eval loss:     0.5104\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  17 loss: 0.52603900\n",
            "      epoch:  17 eval loss:     0.5020\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  18 loss: 0.52008957\n",
            "      epoch:  18 eval loss:     0.5000\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  19 loss: 0.52043462\n",
            "      epoch:  19 eval loss:     0.5033\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  20 loss: 0.52588767\n",
            "      epoch:  20 eval loss:     0.5082\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  21 loss: 0.53225529\n",
            "      epoch:  21 eval loss:     0.5111\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  22 loss: 0.53591979\n",
            "      epoch:  22 eval loss:     0.5108\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  23 loss: 0.53569758\n",
            "      epoch:  23 eval loss:     0.5078\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  24 loss: 0.53221655\n",
            "      epoch:  24 eval loss:     0.5034\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  25 loss: 0.52686089\n",
            "      epoch:  25 eval loss:     0.4988\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  26 loss: 0.52118516\n",
            "      epoch:  26 eval loss:     0.4952\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  27 loss: 0.51634896\n",
            "      epoch:  27 eval loss:     0.4929\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  28 loss: 0.51280171\n",
            "      epoch:  28 eval loss:     0.4919\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  29 loss: 0.51059455\n",
            "      epoch:  29 eval loss:     0.4919\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  30 loss: 0.50953519\n",
            "      epoch:  30 eval loss:     0.4926\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  31 loss: 0.50926238\n",
            "      epoch:  31 eval loss:     0.4935\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  32 loss: 0.50937819\n",
            "      epoch:  32 eval loss:     0.4943\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  33 loss: 0.50953788\n",
            "      epoch:  33 eval loss:     0.4947\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  34 loss: 0.50949281\n",
            "      epoch:  34 eval loss:     0.4946\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  35 loss: 0.50909191\n",
            "      epoch:  35 eval loss:     0.4939\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  36 loss: 0.50827903\n",
            "      epoch:  36 eval loss:     0.4927\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  37 loss: 0.50707400\n",
            "      epoch:  37 eval loss:     0.4911\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  38 loss: 0.50556999\n",
            "      epoch:  38 eval loss:     0.4893\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  39 loss: 0.50390244\n",
            "      epoch:  39 eval loss:     0.4874\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  40 loss: 0.50224853\n",
            "      epoch:  40 eval loss:     0.4856\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  41 loss: 0.50075102\n",
            "      epoch:  41 eval loss:     0.4841\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  42 loss: 0.49950886\n",
            "      epoch:  42 eval loss:     0.4829\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  43 loss: 0.49858665\n",
            "      epoch:  43 eval loss:     0.4819\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  44 loss: 0.49793345\n",
            "      epoch:  44 eval loss:     0.4813\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  45 loss: 0.49741322\n",
            "      epoch:  45 eval loss:     0.4807\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  46 loss: 0.49688187\n",
            "      epoch:  46 eval loss:     0.4801\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  47 loss: 0.49619520\n",
            "      epoch:  47 eval loss:     0.4794\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  48 loss: 0.49523729\n",
            "      epoch:  48 eval loss:     0.4786\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  49 loss: 0.49402109\n",
            "      epoch:  49 eval loss:     0.4778\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  50 loss: 0.49266660\n",
            "      epoch:  50 eval loss:     0.4769\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  51 loss: 0.49129480\n",
            "      epoch:  51 eval loss:     0.4762\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  52 loss: 0.49000356\n",
            "      epoch:  52 eval loss:     0.4756\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  53 loss: 0.48887321\n",
            "      epoch:  53 eval loss:     0.4753\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  54 loss: 0.48793256\n",
            "      epoch:  54 eval loss:     0.4750\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  55 loss: 0.48711327\n",
            "      epoch:  55 eval loss:     0.4747\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  56 loss: 0.48630026\n",
            "      epoch:  56 eval loss:     0.4742\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  57 loss: 0.48540694\n",
            "      epoch:  57 eval loss:     0.4735\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  58 loss: 0.48438218\n",
            "      epoch:  58 eval loss:     0.4726\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  59 loss: 0.48323086\n",
            "      epoch:  59 eval loss:     0.4716\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  60 loss: 0.48201066\n",
            "      epoch:  60 eval loss:     0.4706\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  61 loss: 0.48080710\n",
            "      epoch:  61 eval loss:     0.4696\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  62 loss: 0.47968766\n",
            "      epoch:  62 eval loss:     0.4688\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  63 loss: 0.47868234\n",
            "      epoch:  63 eval loss:     0.4681\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  64 loss: 0.47776482\n",
            "      epoch:  64 eval loss:     0.4674\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  65 loss: 0.47687629\n",
            "      epoch:  65 eval loss:     0.4668\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  66 loss: 0.47596061\n",
            "      epoch:  66 eval loss:     0.4662\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  67 loss: 0.47499877\n",
            "      epoch:  67 eval loss:     0.4655\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  68 loss: 0.47402903\n",
            "      epoch:  68 eval loss:     0.4649\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  69 loss: 0.47311085\n",
            "      epoch:  69 eval loss:     0.4644\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  70 loss: 0.47227404\n",
            "      epoch:  70 eval loss:     0.4638\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  71 loss: 0.47152212\n",
            "      epoch:  71 eval loss:     0.4633\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  72 loss: 0.47082165\n",
            "      epoch:  72 eval loss:     0.4627\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  73 loss: 0.47010061\n",
            "      epoch:  73 eval loss:     0.4620\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  74 loss: 0.46933275\n",
            "      epoch:  74 eval loss:     0.4612\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  75 loss: 0.46853903\n",
            "      epoch:  75 eval loss:     0.4603\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  76 loss: 0.46775293\n",
            "      epoch:  76 eval loss:     0.4595\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  77 loss: 0.46700647\n",
            "      epoch:  77 eval loss:     0.4587\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  78 loss: 0.46630377\n",
            "      epoch:  78 eval loss:     0.4580\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  79 loss: 0.46561080\n",
            "      epoch:  79 eval loss:     0.4571\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  80 loss: 0.46490127\n",
            "      epoch:  80 eval loss:     0.4563\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  81 loss: 0.46417475\n",
            "      epoch:  81 eval loss:     0.4555\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  82 loss: 0.46345749\n",
            "      epoch:  82 eval loss:     0.4547\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  83 loss: 0.46278456\n",
            "      epoch:  83 eval loss:     0.4539\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  84 loss: 0.46215713\n",
            "      epoch:  84 eval loss:     0.4531\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  85 loss: 0.46154562\n",
            "      epoch:  85 eval loss:     0.4523\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  86 loss: 0.46092746\n",
            "      epoch:  86 eval loss:     0.4514\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  87 loss: 0.46029899\n",
            "      epoch:  87 eval loss:     0.4506\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  88 loss: 0.45968717\n",
            "      epoch:  88 eval loss:     0.4497\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  89 loss: 0.45910701\n",
            "      epoch:  89 eval loss:     0.4489\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  90 loss: 0.45853862\n",
            "      epoch:  90 eval loss:     0.4481\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  91 loss: 0.45793939\n",
            "      epoch:  91 eval loss:     0.4473\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  92 loss: 0.45730177\n",
            "      epoch:  92 eval loss:     0.4465\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  93 loss: 0.45665357\n",
            "      epoch:  93 eval loss:     0.4457\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  94 loss: 0.45600349\n",
            "      epoch:  94 eval loss:     0.4450\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  95 loss: 0.45531380\n",
            "      epoch:  95 eval loss:     0.4442\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  96 loss: 0.45458230\n",
            "      epoch:  96 eval loss:     0.4433\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  97 loss: 0.45382667\n",
            "      epoch:  97 eval loss:     0.4424\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  98 loss: 0.45302591\n",
            "      epoch:  98 eval loss:     0.4414\n",
            "             eval accuracy:     0.8087\n",
            "epoch:  99 loss: 0.45219493\n",
            "      epoch:  99 eval loss:     0.4405\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 100 loss: 0.45132726\n",
            "      epoch: 100 eval loss:     0.4396\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 101 loss: 0.45046538\n",
            "      epoch: 101 eval loss:     0.4388\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 102 loss: 0.44960654\n",
            "      epoch: 102 eval loss:     0.4378\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 103 loss: 0.44869348\n",
            "      epoch: 103 eval loss:     0.4368\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 104 loss: 0.44777444\n",
            "      epoch: 104 eval loss:     0.4359\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 105 loss: 0.44686377\n",
            "      epoch: 105 eval loss:     0.4348\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 106 loss: 0.44592622\n",
            "      epoch: 106 eval loss:     0.4337\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 107 loss: 0.44493771\n",
            "      epoch: 107 eval loss:     0.4326\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 108 loss: 0.44392061\n",
            "      epoch: 108 eval loss:     0.4314\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 109 loss: 0.44288582\n",
            "      epoch: 109 eval loss:     0.4302\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 110 loss: 0.44184983\n",
            "      epoch: 110 eval loss:     0.4291\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 111 loss: 0.44080746\n",
            "      epoch: 111 eval loss:     0.4282\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 112 loss: 0.43982124\n",
            "      epoch: 112 eval loss:     0.4273\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 113 loss: 0.43890741\n",
            "      epoch: 113 eval loss:     0.4264\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 114 loss: 0.43802029\n",
            "      epoch: 114 eval loss:     0.4256\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 115 loss: 0.43721402\n",
            "      epoch: 115 eval loss:     0.4249\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 116 loss: 0.43646157\n",
            "      epoch: 116 eval loss:     0.4242\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 117 loss: 0.43576267\n",
            "      epoch: 117 eval loss:     0.4234\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 118 loss: 0.43509081\n",
            "      epoch: 118 eval loss:     0.4226\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 119 loss: 0.43444192\n",
            "      epoch: 119 eval loss:     0.4219\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 120 loss: 0.43377146\n",
            "      epoch: 120 eval loss:     0.4211\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 121 loss: 0.43312308\n",
            "      epoch: 121 eval loss:     0.4204\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 122 loss: 0.43251452\n",
            "      epoch: 122 eval loss:     0.4196\n",
            "             eval accuracy:       0.81\n",
            "epoch: 123 loss: 0.43191415\n",
            "      epoch: 123 eval loss:     0.4189\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 124 loss: 0.43131545\n",
            "      epoch: 124 eval loss:     0.4182\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 125 loss: 0.43074450\n",
            "      epoch: 125 eval loss:     0.4176\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 126 loss: 0.43018422\n",
            "      epoch: 126 eval loss:     0.4170\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 127 loss: 0.42971966\n",
            "      epoch: 127 eval loss:     0.4163\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 128 loss: 0.42929098\n",
            "      epoch: 128 eval loss:     0.4157\n",
            "             eval accuracy:        0.8\n",
            "epoch: 129 loss: 0.42884302\n",
            "      epoch: 129 eval loss:     0.4151\n",
            "             eval accuracy:     0.8012\n",
            "epoch: 130 loss: 0.42837057\n",
            "      epoch: 130 eval loss:     0.4144\n",
            "             eval accuracy:        0.8\n",
            "epoch: 131 loss: 0.42789069\n",
            "      epoch: 131 eval loss:     0.4137\n",
            "             eval accuracy:        0.8\n",
            "epoch: 132 loss: 0.42743847\n",
            "      epoch: 132 eval loss:     0.4133\n",
            "             eval accuracy:     0.8037\n",
            "epoch: 133 loss: 0.42702994\n",
            "      epoch: 133 eval loss:     0.4129\n",
            "             eval accuracy:     0.8037\n",
            "epoch: 134 loss: 0.42662695\n",
            "      epoch: 134 eval loss:     0.4126\n",
            "             eval accuracy:     0.8037\n",
            "epoch: 135 loss: 0.42620626\n",
            "      epoch: 135 eval loss:     0.4123\n",
            "             eval accuracy:      0.805\n",
            "epoch: 136 loss: 0.42578396\n",
            "      epoch: 136 eval loss:     0.4121\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 137 loss: 0.42539489\n",
            "      epoch: 137 eval loss:     0.4118\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 138 loss: 0.42501071\n",
            "      epoch: 138 eval loss:     0.4114\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 139 loss: 0.42463186\n",
            "      epoch: 139 eval loss:     0.4111\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 140 loss: 0.42424521\n",
            "      epoch: 140 eval loss:     0.4108\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 141 loss: 0.42385006\n",
            "      epoch: 141 eval loss:     0.4103\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 142 loss: 0.42344695\n",
            "      epoch: 142 eval loss:     0.4099\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 143 loss: 0.42294818\n",
            "      epoch: 143 eval loss:     0.4093\n",
            "             eval accuracy:     0.8112\n",
            "epoch: 144 loss: 0.42237717\n",
            "      epoch: 144 eval loss:     0.4087\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 145 loss: 0.42180493\n",
            "      epoch: 145 eval loss:     0.4080\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 146 loss: 0.42115667\n",
            "      epoch: 146 eval loss:     0.4073\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 147 loss: 0.42049384\n",
            "      epoch: 147 eval loss:     0.4064\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 148 loss: 0.41982844\n",
            "      epoch: 148 eval loss:     0.4056\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 149 loss: 0.41918963\n",
            "      epoch: 149 eval loss:     0.4050\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 150 loss: 0.41855371\n",
            "      epoch: 150 eval loss:     0.4043\n",
            "             eval accuracy:     0.8037\n",
            "epoch: 151 loss: 0.41793829\n",
            "      epoch: 151 eval loss:     0.4038\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 152 loss: 0.41729891\n",
            "      epoch: 152 eval loss:     0.4030\n",
            "             eval accuracy:     0.8025\n",
            "epoch: 153 loss: 0.41659236\n",
            "      epoch: 153 eval loss:     0.4023\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 154 loss: 0.41585883\n",
            "      epoch: 154 eval loss:     0.4015\n",
            "             eval accuracy:     0.8037\n",
            "epoch: 155 loss: 0.41514990\n",
            "      epoch: 155 eval loss:     0.4007\n",
            "             eval accuracy:     0.8062\n",
            "epoch: 156 loss: 0.41443911\n",
            "      epoch: 156 eval loss:     0.4001\n",
            "             eval accuracy:       0.81\n",
            "epoch: 157 loss: 0.41364625\n",
            "      epoch: 157 eval loss:     0.3990\n",
            "             eval accuracy:      0.805\n",
            "epoch: 158 loss: 0.41282934\n",
            "      epoch: 158 eval loss:     0.3981\n",
            "             eval accuracy:     0.8075\n",
            "epoch: 159 loss: 0.41199738\n",
            "      epoch: 159 eval loss:     0.3972\n",
            "             eval accuracy:       0.81\n",
            "epoch: 160 loss: 0.41115093\n",
            "      epoch: 160 eval loss:     0.3962\n",
            "             eval accuracy:     0.8087\n",
            "epoch: 161 loss: 0.41027808\n",
            "      epoch: 161 eval loss:     0.3954\n",
            "             eval accuracy:     0.8125\n",
            "epoch: 162 loss: 0.40939856\n",
            "      epoch: 162 eval loss:     0.3943\n",
            "             eval accuracy:     0.8138\n",
            "epoch: 163 loss: 0.40850163\n",
            "      epoch: 163 eval loss:     0.3935\n",
            "             eval accuracy:     0.8163\n",
            "epoch: 164 loss: 0.40757114\n",
            "      epoch: 164 eval loss:     0.3924\n",
            "             eval accuracy:      0.815\n",
            "epoch: 165 loss: 0.40660962\n",
            "      epoch: 165 eval loss:     0.3913\n",
            "             eval accuracy:     0.8163\n",
            "epoch: 166 loss: 0.40561524\n",
            "      epoch: 166 eval loss:     0.3903\n",
            "             eval accuracy:     0.8175\n",
            "epoch: 167 loss: 0.40458345\n",
            "      epoch: 167 eval loss:     0.3890\n",
            "             eval accuracy:     0.8175\n",
            "epoch: 168 loss: 0.40352967\n",
            "      epoch: 168 eval loss:     0.3879\n",
            "             eval accuracy:     0.8163\n",
            "epoch: 169 loss: 0.40243244\n",
            "      epoch: 169 eval loss:     0.3866\n",
            "             eval accuracy:     0.8163\n",
            "epoch: 170 loss: 0.40129727\n",
            "      epoch: 170 eval loss:     0.3854\n",
            "             eval accuracy:     0.8175\n",
            "epoch: 171 loss: 0.40015772\n",
            "      epoch: 171 eval loss:     0.3841\n",
            "             eval accuracy:     0.8188\n",
            "epoch: 172 loss: 0.39899734\n",
            "      epoch: 172 eval loss:     0.3827\n",
            "             eval accuracy:     0.8188\n",
            "epoch: 173 loss: 0.39778945\n",
            "      epoch: 173 eval loss:     0.3815\n",
            "             eval accuracy:     0.8188\n",
            "epoch: 174 loss: 0.39655825\n",
            "      epoch: 174 eval loss:     0.3801\n",
            "             eval accuracy:     0.8213\n",
            "epoch: 175 loss: 0.39528656\n",
            "      epoch: 175 eval loss:     0.3790\n",
            "             eval accuracy:      0.825\n",
            "epoch: 176 loss: 0.39400792\n",
            "      epoch: 176 eval loss:     0.3776\n",
            "             eval accuracy:      0.825\n",
            "epoch: 177 loss: 0.39271143\n",
            "      epoch: 177 eval loss:     0.3768\n",
            "             eval accuracy:     0.8238\n",
            "epoch: 178 loss: 0.39135027\n",
            "      epoch: 178 eval loss:     0.3757\n",
            "             eval accuracy:      0.825\n",
            "epoch: 179 loss: 0.39001784\n",
            "      epoch: 179 eval loss:     0.3751\n",
            "             eval accuracy:     0.8263\n",
            "epoch: 180 loss: 0.38875416\n",
            "      epoch: 180 eval loss:     0.3737\n",
            "             eval accuracy:     0.8288\n",
            "epoch: 181 loss: 0.38760626\n",
            "      epoch: 181 eval loss:     0.3730\n",
            "             eval accuracy:     0.8275\n",
            "epoch: 182 loss: 0.38633963\n",
            "      epoch: 182 eval loss:     0.3711\n",
            "             eval accuracy:     0.8313\n",
            "epoch: 183 loss: 0.38448423\n",
            "      epoch: 183 eval loss:     0.3696\n",
            "             eval accuracy:     0.8325\n",
            "epoch: 184 loss: 0.38282064\n",
            "      epoch: 184 eval loss:     0.3684\n",
            "             eval accuracy:       0.83\n",
            "epoch: 185 loss: 0.38168833\n",
            "      epoch: 185 eval loss:     0.3670\n",
            "             eval accuracy:     0.8325\n",
            "epoch: 186 loss: 0.38042745\n",
            "      epoch: 186 eval loss:     0.3652\n",
            "             eval accuracy:     0.8325\n",
            "epoch: 187 loss: 0.37872341\n",
            "      epoch: 187 eval loss:     0.3636\n",
            "             eval accuracy:     0.8338\n",
            "epoch: 188 loss: 0.37706342\n",
            "      epoch: 188 eval loss:     0.3623\n",
            "             eval accuracy:      0.835\n",
            "epoch: 189 loss: 0.37580445\n",
            "      epoch: 189 eval loss:     0.3607\n",
            "             eval accuracy:     0.8325\n",
            "epoch: 190 loss: 0.37459347\n",
            "      epoch: 190 eval loss:     0.3591\n",
            "             eval accuracy:     0.8388\n",
            "epoch: 191 loss: 0.37304863\n",
            "      epoch: 191 eval loss:     0.3569\n",
            "             eval accuracy:     0.8338\n",
            "epoch: 192 loss: 0.37143913\n",
            "      epoch: 192 eval loss:     0.3552\n",
            "             eval accuracy:     0.8375\n",
            "epoch: 193 loss: 0.37000060\n",
            "      epoch: 193 eval loss:     0.3540\n",
            "             eval accuracy:     0.8413\n",
            "epoch: 194 loss: 0.36875471\n",
            "      epoch: 194 eval loss:     0.3521\n",
            "             eval accuracy:       0.84\n",
            "epoch: 195 loss: 0.36752847\n",
            "      epoch: 195 eval loss:     0.3507\n",
            "             eval accuracy:      0.845\n",
            "epoch: 196 loss: 0.36622182\n",
            "      epoch: 196 eval loss:     0.3485\n",
            "             eval accuracy:     0.8438\n",
            "epoch: 197 loss: 0.36489901\n",
            "      epoch: 197 eval loss:     0.3472\n",
            "             eval accuracy:     0.8475\n",
            "epoch: 198 loss: 0.36352667\n",
            "      epoch: 198 eval loss:     0.3455\n",
            "             eval accuracy:     0.8475\n",
            "epoch: 199 loss: 0.36223391\n",
            "      epoch: 199 eval loss:     0.3442\n",
            "             eval accuracy:     0.8475\n",
            "epoch: 200 loss: 0.36103261\n",
            "      epoch: 200 eval loss:     0.3427\n",
            "             eval accuracy:     0.8475\n",
            "epoch: 201 loss: 0.35991690\n",
            "      epoch: 201 eval loss:     0.3410\n",
            "             eval accuracy:     0.8487\n",
            "epoch: 202 loss: 0.35892347\n",
            "      epoch: 202 eval loss:     0.3404\n",
            "             eval accuracy:     0.8512\n",
            "epoch: 203 loss: 0.35808975\n",
            "      epoch: 203 eval loss:     0.3389\n",
            "             eval accuracy:     0.8537\n",
            "epoch: 204 loss: 0.35765043\n",
            "      epoch: 204 eval loss:     0.3398\n",
            "             eval accuracy:     0.8537\n",
            "epoch: 205 loss: 0.35743275\n",
            "      epoch: 205 eval loss:     0.3375\n",
            "             eval accuracy:      0.855\n",
            "epoch: 206 loss: 0.35692477\n",
            "      epoch: 206 eval loss:     0.3364\n",
            "             eval accuracy:     0.8562\n",
            "epoch: 207 loss: 0.35477179\n",
            "      epoch: 207 eval loss:     0.3345\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 208 loss: 0.35344422\n",
            "      epoch: 208 eval loss:     0.3339\n",
            "             eval accuracy:     0.8575\n",
            "epoch: 209 loss: 0.35359460\n",
            "      epoch: 209 eval loss:     0.3342\n",
            "             eval accuracy:     0.8575\n",
            "epoch: 210 loss: 0.35309586\n",
            "      epoch: 210 eval loss:     0.3317\n",
            "             eval accuracy:     0.8575\n",
            "epoch: 211 loss: 0.35165262\n",
            "      epoch: 211 eval loss:     0.3306\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 212 loss: 0.35094979\n",
            "      epoch: 212 eval loss:     0.3310\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 213 loss: 0.35108921\n",
            "      epoch: 213 eval loss:     0.3292\n",
            "             eval accuracy:     0.8587\n",
            "epoch: 214 loss: 0.35054848\n",
            "      epoch: 214 eval loss:     0.3284\n",
            "             eval accuracy:       0.86\n",
            "epoch: 215 loss: 0.34934235\n",
            "      epoch: 215 eval loss:     0.3282\n",
            "             eval accuracy:       0.86\n",
            "epoch: 216 loss: 0.34913433\n",
            "      epoch: 216 eval loss:     0.3273\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 217 loss: 0.34919813\n",
            "      epoch: 217 eval loss:     0.3268\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 218 loss: 0.34829721\n",
            "      epoch: 218 eval loss:     0.3257\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 219 loss: 0.34761468\n",
            "      epoch: 219 eval loss:     0.3250\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 220 loss: 0.34765673\n",
            "      epoch: 220 eval loss:     0.3250\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 221 loss: 0.34732825\n",
            "      epoch: 221 eval loss:     0.3235\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 222 loss: 0.34661946\n",
            "      epoch: 222 eval loss:     0.3230\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 223 loss: 0.34625661\n",
            "      epoch: 223 eval loss:     0.3231\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 224 loss: 0.34624365\n",
            "      epoch: 224 eval loss:     0.3219\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 225 loss: 0.34596381\n",
            "      epoch: 225 eval loss:     0.3215\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 226 loss: 0.34537214\n",
            "      epoch: 226 eval loss:     0.3209\n",
            "             eval accuracy:      0.865\n",
            "epoch: 227 loss: 0.34503537\n",
            "      epoch: 227 eval loss:     0.3204\n",
            "             eval accuracy:      0.865\n",
            "epoch: 228 loss: 0.34497720\n",
            "      epoch: 228 eval loss:     0.3210\n",
            "             eval accuracy:      0.865\n",
            "epoch: 229 loss: 0.34476060\n",
            "      epoch: 229 eval loss:     0.3201\n",
            "             eval accuracy:      0.865\n",
            "epoch: 230 loss: 0.34433445\n",
            "      epoch: 230 eval loss:     0.3198\n",
            "             eval accuracy:      0.865\n",
            "epoch: 231 loss: 0.34392482\n",
            "      epoch: 231 eval loss:     0.3195\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 232 loss: 0.34369880\n",
            "      epoch: 232 eval loss:     0.3192\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 233 loss: 0.34357628\n",
            "      epoch: 233 eval loss:     0.3196\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 234 loss: 0.34338754\n",
            "      epoch: 234 eval loss:     0.3189\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 235 loss: 0.34307444\n",
            "      epoch: 235 eval loss:     0.3188\n",
            "             eval accuracy:      0.865\n",
            "epoch: 236 loss: 0.34270915\n",
            "      epoch: 236 eval loss:     0.3186\n",
            "             eval accuracy:      0.865\n",
            "epoch: 237 loss: 0.34240672\n",
            "      epoch: 237 eval loss:     0.3184\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 238 loss: 0.34222603\n",
            "      epoch: 238 eval loss:     0.3184\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 239 loss: 0.34211624\n",
            "      epoch: 239 eval loss:     0.3179\n",
            "             eval accuracy:     0.8612\n",
            "epoch: 240 loss: 0.34200740\n",
            "      epoch: 240 eval loss:     0.3182\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 241 loss: 0.34180072\n",
            "      epoch: 241 eval loss:     0.3179\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 242 loss: 0.34154245\n",
            "      epoch: 242 eval loss:     0.3179\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 243 loss: 0.34117207\n",
            "      epoch: 243 eval loss:     0.3173\n",
            "             eval accuracy:      0.865\n",
            "epoch: 244 loss: 0.34084710\n",
            "      epoch: 244 eval loss:     0.3170\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 245 loss: 0.34059235\n",
            "      epoch: 245 eval loss:     0.3168\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 246 loss: 0.34041575\n",
            "      epoch: 246 eval loss:     0.3165\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 247 loss: 0.34027553\n",
            "      epoch: 247 eval loss:     0.3163\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 248 loss: 0.34011748\n",
            "      epoch: 248 eval loss:     0.3159\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 249 loss: 0.33994451\n",
            "      epoch: 249 eval loss:     0.3158\n",
            "             eval accuracy:       0.87\n",
            "epoch: 250 loss: 0.33970818\n",
            "      epoch: 250 eval loss:     0.3155\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 251 loss: 0.33947462\n",
            "      epoch: 251 eval loss:     0.3152\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 252 loss: 0.33922634\n",
            "      epoch: 252 eval loss:     0.3149\n",
            "             eval accuracy:      0.865\n",
            "epoch: 253 loss: 0.33899313\n",
            "      epoch: 253 eval loss:     0.3148\n",
            "             eval accuracy:      0.865\n",
            "epoch: 254 loss: 0.33878693\n",
            "      epoch: 254 eval loss:     0.3148\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 255 loss: 0.33859602\n",
            "      epoch: 255 eval loss:     0.3147\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 256 loss: 0.33842573\n",
            "      epoch: 256 eval loss:     0.3147\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 257 loss: 0.33826712\n",
            "      epoch: 257 eval loss:     0.3148\n",
            "             eval accuracy:     0.8712\n",
            "epoch: 258 loss: 0.33812520\n",
            "      epoch: 258 eval loss:     0.3149\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 259 loss: 0.33796272\n",
            "      epoch: 259 eval loss:     0.3147\n",
            "             eval accuracy:     0.8712\n",
            "epoch: 260 loss: 0.33778408\n",
            "      epoch: 260 eval loss:     0.3148\n",
            "             eval accuracy:      0.865\n",
            "epoch: 261 loss: 0.33760831\n",
            "      epoch: 261 eval loss:     0.3148\n",
            "             eval accuracy:     0.8712\n",
            "epoch: 262 loss: 0.33744550\n",
            "      epoch: 262 eval loss:     0.3150\n",
            "             eval accuracy:      0.865\n",
            "epoch: 263 loss: 0.33729237\n",
            "      epoch: 263 eval loss:     0.3149\n",
            "             eval accuracy:       0.87\n",
            "epoch: 264 loss: 0.33715475\n",
            "      epoch: 264 eval loss:     0.3150\n",
            "             eval accuracy:      0.865\n",
            "epoch: 265 loss: 0.33706105\n",
            "      epoch: 265 eval loss:     0.3150\n",
            "             eval accuracy:     0.8725\n",
            "epoch: 266 loss: 0.33707187\n",
            "      epoch: 266 eval loss:     0.3153\n",
            "             eval accuracy:       0.87\n",
            "epoch: 267 loss: 0.33700764\n",
            "      epoch: 267 eval loss:     0.3151\n",
            "             eval accuracy:     0.8725\n",
            "epoch: 268 loss: 0.33700457\n",
            "      epoch: 268 eval loss:     0.3152\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 269 loss: 0.33683637\n",
            "      epoch: 269 eval loss:     0.3148\n",
            "             eval accuracy:     0.8737\n",
            "epoch: 270 loss: 0.33654386\n",
            "      epoch: 270 eval loss:     0.3148\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 271 loss: 0.33611280\n",
            "      epoch: 271 eval loss:     0.3144\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 272 loss: 0.33572862\n",
            "      epoch: 272 eval loss:     0.3144\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 273 loss: 0.33552852\n",
            "      epoch: 273 eval loss:     0.3147\n",
            "             eval accuracy:      0.865\n",
            "epoch: 274 loss: 0.33550584\n",
            "      epoch: 274 eval loss:     0.3146\n",
            "             eval accuracy:     0.8725\n",
            "epoch: 275 loss: 0.33555400\n",
            "      epoch: 275 eval loss:     0.3146\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 276 loss: 0.33550140\n",
            "      epoch: 276 eval loss:     0.3142\n",
            "             eval accuracy:     0.8712\n",
            "epoch: 277 loss: 0.33535770\n",
            "      epoch: 277 eval loss:     0.3142\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 278 loss: 0.33502021\n",
            "      epoch: 278 eval loss:     0.3139\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 279 loss: 0.33466664\n",
            "      epoch: 279 eval loss:     0.3139\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 280 loss: 0.33441857\n",
            "      epoch: 280 eval loss:     0.3136\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 281 loss: 0.33425501\n",
            "      epoch: 281 eval loss:     0.3135\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 282 loss: 0.33421180\n",
            "      epoch: 282 eval loss:     0.3137\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 283 loss: 0.33420712\n",
            "      epoch: 283 eval loss:     0.3137\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 284 loss: 0.33420563\n",
            "      epoch: 284 eval loss:     0.3142\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 285 loss: 0.33412638\n",
            "      epoch: 285 eval loss:     0.3138\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 286 loss: 0.33405674\n",
            "      epoch: 286 eval loss:     0.3137\n",
            "             eval accuracy:     0.8687\n",
            "epoch: 287 loss: 0.33380824\n",
            "      epoch: 287 eval loss:     0.3132\n",
            "             eval accuracy:      0.865\n",
            "epoch: 288 loss: 0.33351445\n",
            "      epoch: 288 eval loss:     0.3135\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 289 loss: 0.33320805\n",
            "      epoch: 289 eval loss:     0.3137\n",
            "             eval accuracy:      0.865\n",
            "epoch: 290 loss: 0.33301774\n",
            "      epoch: 290 eval loss:     0.3137\n",
            "             eval accuracy:      0.865\n",
            "epoch: 291 loss: 0.33290422\n",
            "      epoch: 291 eval loss:     0.3137\n",
            "             eval accuracy:      0.865\n",
            "epoch: 292 loss: 0.33287731\n",
            "      epoch: 292 eval loss:     0.3137\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 293 loss: 0.33287048\n",
            "      epoch: 293 eval loss:     0.3142\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 294 loss: 0.33280221\n",
            "      epoch: 294 eval loss:     0.3142\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 295 loss: 0.33270994\n",
            "      epoch: 295 eval loss:     0.3140\n",
            "             eval accuracy:     0.8662\n",
            "epoch: 296 loss: 0.33251807\n",
            "      epoch: 296 eval loss:     0.3137\n",
            "             eval accuracy:     0.8625\n",
            "epoch: 297 loss: 0.33232468\n",
            "      epoch: 297 eval loss:     0.3136\n",
            "             eval accuracy:     0.8675\n",
            "epoch: 298 loss: 0.33213061\n",
            "      epoch: 298 eval loss:     0.3135\n",
            "             eval accuracy:     0.8637\n",
            "epoch: 299 loss: 0.33198076\n",
            "      epoch: 299 eval loss:     0.3136\n",
            "             eval accuracy:     0.8637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Confusion matrix and f1 score\n",
        "import scipy\n",
        "\n",
        "def confusion_matrix(x,y,num_classes = 2):\n",
        "  x = x.detach().numpy()\n",
        "  y = y.detach().numpy()\n",
        "  x = np.argmax(x,axis=1)\n",
        "  data = np.ones(y.shape[0], dtype=np.int64)\n",
        "  ind = np.logical_and(x < num_classes, y < num_classes)\n",
        "  if not np.all(ind):\n",
        "      x = x[ind]\n",
        "      y = y[ind]\n",
        "      data = data[ind]\n",
        "\n",
        "\n",
        "  cm = scipy.sparse.coo_matrix((data,(x,y)),shape=(num_classes,num_classes),dtype=np.int64).toarray()\n",
        "  cm = np.nan_to_num(cm)\n",
        "\n",
        "  return cm\n",
        "\n",
        "## Confusion matrix test\n",
        "x = torch.tensor(np.random.randint(2, size=(5,2)))\n",
        "y = torch.tensor(np.random.randint(2, size=5))\n",
        "\n",
        "print(x,y)\n",
        "print(confusion_matrix(x,y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nl5ymiJYlbR",
        "outputId": "4dc7f829-67a0-4f7d-dba5-b8db7720cbe7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [0, 1],\n",
            "        [0, 0],\n",
            "        [0, 1],\n",
            "        [0, 0]]) tensor([1, 1, 1, 0, 1])\n",
            "[[0 2]\n",
            " [1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model performance on Test data\n",
        "\n",
        "y_test_pred = model(X_test)\n",
        "test_accuracy = accu(y_test_pred,y_test)\n",
        "test_cm = confusion_matrix(y_test_pred,y_test)\n",
        "\n",
        "print(f\"Test Accuracy:{test_accuracy:2.4}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(test_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yckqs0Ghuehz",
        "outputId": "57d48b36-fa96-4dc5-95fe-5c9e3a49f3eb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.8625\n",
            "Confusion Matrix:\n",
            "[[1534  202]\n",
            " [  73  191]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XZWmdiyAukIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}